<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: module gen_ai_hub.proxy.langchain.google_vertexai</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head><body bgcolor="#f0f0f8">

<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="#7799ee">
<td valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial">&nbsp;<br><big><big><strong><a href="gen_ai_hub.html"><font color="#ffffff">gen_ai_hub</font></a>.<a href="gen_ai_hub.proxy.html"><font color="#ffffff">proxy</font></a>.<a href="gen_ai_hub.proxy.langchain.html"><font color="#ffffff">langchain</font></a>.google_vertexai</strong></big></big></font></td
><td align=right valign=bottom
><font color="#ffffff" face="helvetica, arial"><a href=".">index</a><br><a href="file:/home/jenkins/agent/workspace/ation_generative-ai-hub-sdk_main/gen_ai_hub/proxy/langchain/google_vertexai.py">/home/jenkins/agent/workspace/ation_generative-ai-hub-sdk_main/gen_ai_hub/proxy/langchain/google_vertexai.py</a></font></td></tr></table>
    <p></p>
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ee77aa">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Classes</strong></big></font></td></tr>
    
<tr><td bgcolor="#ee77aa"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl>
<dt><font face="helvetica, arial"><a href="langchain_google_vertexai.chat_models.html#ChatVertexAI">langchain_google_vertexai.chat_models.ChatVertexAI</a>(<a href="langchain_google_vertexai._base.html#_VertexAICommon">langchain_google_vertexai._base._VertexAICommon</a>, <a href="langchain_core.language_models.chat_models.html#BaseChatModel">langchain_core.language_models.chat_models.BaseChatModel</a>)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="gen_ai_hub.proxy.langchain.google_vertexai.html#ChatVertexAI">ChatVertexAI</a>
</font></dt></dl>
</dd>
</dl>
 <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="ChatVertexAI">class <strong>ChatVertexAI</strong></a>(<a href="langchain_google_vertexai.chat_models.html#ChatVertexAI">langchain_google_vertexai.chat_models.ChatVertexAI</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt><a href="#ChatVertexAI">ChatVertexAI</a>(*args,&nbsp;model:&nbsp;str&nbsp;=&nbsp;'',&nbsp;proxy_model_name:&nbsp;str&nbsp;=&nbsp;'',&nbsp;model_id:&nbsp;str&nbsp;=&nbsp;'',&nbsp;deployment_id:&nbsp;str&nbsp;=&nbsp;'',&nbsp;config_id:&nbsp;str&nbsp;=&nbsp;'',&nbsp;config_name:&nbsp;str&nbsp;=&nbsp;'',&nbsp;proxy_client:&nbsp;Optional[gen_ai_hub.proxy.core.base.BaseProxyClient]&nbsp;=&nbsp;None,&nbsp;name:&nbsp;Optional[str]&nbsp;=&nbsp;None,&nbsp;cache:&nbsp;Union[langchain_core.caches.BaseCache,&nbsp;bool,&nbsp;NoneType]&nbsp;=&nbsp;None,&nbsp;verbose:&nbsp;bool&nbsp;=&nbsp;&amp;lt;factory&amp;gt;,&nbsp;callbacks:&nbsp;Union[list[langchain_core.callbacks.base.BaseCallbackHandler],&nbsp;langchain_core.callbacks.base.BaseCallbackManager,&nbsp;NoneType]&nbsp;=&nbsp;None,&nbsp;tags:&nbsp;Optional[list[str]]&nbsp;=&nbsp;None,&nbsp;metadata:&nbsp;Optional[dict[str,&nbsp;Any]]&nbsp;=&nbsp;None,&nbsp;custom_get_token_ids:&nbsp;Optional[Callable[[str],&nbsp;list[int]]]&nbsp;=&nbsp;None,&nbsp;callback_manager:&nbsp;Optional[langchain_core.callbacks.base.BaseCallbackManager]&nbsp;=&nbsp;None,&nbsp;rate_limiter:&nbsp;Optional[langchain_core.rate_limiters.BaseRateLimiter]&nbsp;=&nbsp;None,&nbsp;disable_streaming:&nbsp;Union[bool,&nbsp;Literal['tool_calling']]&nbsp;=&nbsp;False,&nbsp;client:&nbsp;Any&nbsp;=&nbsp;None,&nbsp;async_client:&nbsp;Any&nbsp;=&nbsp;None,&nbsp;project:&nbsp;Optional[str]&nbsp;=&nbsp;None,&nbsp;location:&nbsp;str&nbsp;=&nbsp;'us-central1',&nbsp;request_parallelism:&nbsp;int&nbsp;=&nbsp;5,&nbsp;max_retries:&nbsp;int&nbsp;=&nbsp;6,&nbsp;stop_sequences:&nbsp;Optional[List[str]]&nbsp;=&nbsp;None,&nbsp;full_model_name:&nbsp;Optional[str]&nbsp;=&nbsp;None,&nbsp;client_options:&nbsp;Optional[google.api_core.client_options.ClientOptions]&nbsp;=&nbsp;None,&nbsp;base_url:&nbsp;Optional[str]&nbsp;=&nbsp;None,&nbsp;api_transport:&nbsp;Optional[str]&nbsp;=&nbsp;None,&nbsp;default_metadata:&nbsp;Sequence[Tuple[str,&nbsp;str]]&nbsp;=&nbsp;&amp;lt;factory&amp;gt;,&nbsp;additional_headers:&nbsp;Optional[Dict[str,&nbsp;str]]&nbsp;=&nbsp;None,&nbsp;client_cert_source:&nbsp;Optional[Callable[[],&nbsp;Tuple[bytes,&nbsp;bytes]]]&nbsp;=&nbsp;None,&nbsp;credentials:&nbsp;Any&nbsp;=&nbsp;None,&nbsp;endpoint_version:&nbsp;Literal['v1',&nbsp;'v1beta1']&nbsp;=&nbsp;'v1beta1',&nbsp;client_preview:&nbsp;Any&nbsp;=&nbsp;None,&nbsp;temperature:&nbsp;Optional[float]&nbsp;=&nbsp;None,&nbsp;max_tokens:&nbsp;Optional[int]&nbsp;=&nbsp;None,&nbsp;top_p:&nbsp;Optional[float]&nbsp;=&nbsp;None,&nbsp;top_k:&nbsp;Optional[int]&nbsp;=&nbsp;None,&nbsp;n:&nbsp;int&nbsp;=&nbsp;1,&nbsp;seed:&nbsp;Optional[int]&nbsp;=&nbsp;None,&nbsp;streaming:&nbsp;bool&nbsp;=&nbsp;False,&nbsp;model_family:&nbsp;Optional[langchain_google_vertexai._utils.GoogleModelFamily]&nbsp;=&nbsp;None,&nbsp;safety_settings:&nbsp;Optional[SafetySettingsType]&nbsp;=&nbsp;None,&nbsp;tuned_model_name:&nbsp;Optional[str]&nbsp;=&nbsp;None,&nbsp;examples:&nbsp;Optional[List[langchain_core.messages.base.BaseMessage]]&nbsp;=&nbsp;None,&nbsp;convert_system_message_to_human:&nbsp;bool&nbsp;=&nbsp;False,&nbsp;response_mime_type:&nbsp;Optional[str]&nbsp;=&nbsp;None,&nbsp;response_schema:&nbsp;Optional[Dict[str,&nbsp;Any]]&nbsp;=&nbsp;None,&nbsp;cached_content:&nbsp;Optional[str]&nbsp;=&nbsp;None,&nbsp;logprobs:&nbsp;Union[bool,&nbsp;int]&nbsp;=&nbsp;False,&nbsp;labels:&nbsp;Optional[Dict[str,&nbsp;str]]&nbsp;=&nbsp;None,&nbsp;perform_literal_eval_on_string_raw_content:&nbsp;bool&nbsp;=&nbsp;True,&nbsp;**kwargs)&nbsp;-&amp;gt;&nbsp;None<br>
&nbsp;<br>
Drop-in&nbsp;replacement&nbsp;for&nbsp;langchain_google_vertexai.<a href="#ChatVertexAI">ChatVertexAI</a>.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="gen_ai_hub.proxy.langchain.google_vertexai.html#ChatVertexAI">ChatVertexAI</a></dd>
<dd><a href="langchain_google_vertexai.chat_models.html#ChatVertexAI">langchain_google_vertexai.chat_models.ChatVertexAI</a></dd>
<dd><a href="langchain_google_vertexai._base.html#_VertexAICommon">langchain_google_vertexai._base._VertexAICommon</a></dd>
<dd><a href="langchain_google_vertexai._base.html#_VertexAIBase">langchain_google_vertexai._base._VertexAIBase</a></dd>
<dd><a href="langchain_core.language_models.chat_models.html#BaseChatModel">langchain_core.language_models.chat_models.BaseChatModel</a></dd>
<dd><a href="langchain_core.language_models.base.html#BaseLanguageModel[BaseMessage]">langchain_core.language_models.base.BaseLanguageModel[BaseMessage]</a></dd>
<dd><a href="langchain_core.language_models.base.html#BaseLanguageModel">langchain_core.language_models.base.BaseLanguageModel</a></dd>
<dd><a href="langchain_core.runnables.base.html#RunnableSerializable[Union[PromptValue, str, Sequence[Union[BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], ~LanguageModelOutputVar]">langchain_core.runnables.base.RunnableSerializable[Union[PromptValue, str, Sequence[Union[BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], ~LanguageModelOutputVar]</a></dd>
<dd><a href="langchain_core.runnables.base.html#RunnableSerializable">langchain_core.runnables.base.RunnableSerializable</a></dd>
<dd><a href="langchain_core.load.serializable.html#Serializable">langchain_core.load.serializable.Serializable</a></dd>
<dd><a href="pydantic.main.html#BaseModel">pydantic.main.BaseModel</a></dd>
<dd><a href="langchain_core.runnables.base.html#Runnable">langchain_core.runnables.base.Runnable</a></dd>
<dd><a href="typing.html#Generic">typing.Generic</a></dd>
<dd><a href="abc.html#ABC">abc.ABC</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="ChatVertexAI-__init__"><strong>__init__</strong></a>(self, *args, model: str = '', proxy_model_name: str = '', model_id: str = '', deployment_id: str = '', model_name: str = '', config_id: str = '', config_name: str = '', proxy_client: Optional[gen_ai_hub.proxy.core.base.BaseProxyClient] = None, **kwargs)</dt><dd><tt>Needed&nbsp;for&nbsp;mypy&nbsp;typing&nbsp;to&nbsp;recognize&nbsp;model_name&nbsp;as&nbsp;a&nbsp;valid&nbsp;arg.</tt></dd></dl>

<hr>
Class methods defined here:<br>
<dl><dt><a name="ChatVertexAI-validate_params_base"><strong>validate_params_base</strong></a>(values: dict) -&gt; dict<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Overrides&nbsp;langchain_google_vertexai._base._VertexAIBase&nbsp;-&gt;&nbsp;validate_params_base.<br>
Original&nbsp;method&nbsp;handles&nbsp;some&nbsp;endpoint&nbsp;specific&nbsp;initialization&nbsp;details&nbsp;not&nbsp;required<br>
for&nbsp;Generative&nbsp;AI&nbsp;Hub&nbsp;endpoints.</tt></dd></dl>

<hr>
Readonly properties defined here:<br>
<dl><dt><strong>async_prediction_client</strong></dt>
<dd><tt>Overrides&nbsp;langchain_google_vertexai._base._VertexAIBase&nbsp;-&gt;&nbsp;async_prediction_client.<br>
Returns&nbsp;PredictionServiceAsyncClient&nbsp;of&nbsp;Generative&nbsp;AI&nbsp;Hub&nbsp;VertexAI&nbsp;integration.</tt></dd>
</dl>
<dl><dt><strong>prediction_client</strong></dt>
<dd><tt>Overrides&nbsp;langchain_google_vertexai._base._VertexAIBase&nbsp;-&gt;&nbsp;prediction_client.<br>
Returns&nbsp;PredictionServiceClient&nbsp;of&nbsp;Generative&nbsp;AI&nbsp;Hub&nbsp;VertexAI&nbsp;integration.</tt></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>__abstractmethods__</strong> = frozenset()</dl>

<dl><dt><strong>__class_vars__</strong> = {'task_executor'}</dl>

<dl><dt><strong>__parameters__</strong> = ()</dl>

<dl><dt><strong>__private_attributes__</strong> = {}</dl>

<dl><dt><strong>__pydantic_complete__</strong> = True</dl>

<dl><dt><strong>__pydantic_computed_fields__</strong> = {}</dl>

<dl><dt><strong>__pydantic_core_schema__</strong> = {'function': {'function': &lt;function ChatVertexAI.validate_environment&gt;, 'type': 'no-info'}, 'metadata': {'pydantic_js_functions': [&lt;bound method BaseModel.__get_pydantic_json_sche...b.proxy.langchain.google_vertexai.ChatVertexAI'&gt;&gt;]}, 'ref': 'gen_ai_hub.proxy.langchain.google_vertexai.ChatVertexAI:140673055175728', 'schema': {'function': {'function': &lt;function ChatVertexAI.validate_labels&gt;, 'type': 'no-info'}, 'schema': {'function': {'function': &lt;function _VertexAIBase.validate_project&gt;, 'type': 'no-info'}, 'schema': {'cls': &lt;class 'gen_ai_hub.proxy.langchain.google_vertexai.ChatVertexAI'&gt;, 'config': {'extra_fields_behavior': 'allow', 'populate_by_name': True, 'title': 'ChatVertexAI'}, 'custom_init': True, 'root_model': False, 'schema': {'function': {'function': &lt;bound method ChatVertexAI.validate_params_base ...b.proxy.langchain.google_vertexai.ChatVertexAI'&gt;&gt;, 'type': 'no-info'}, 'schema': {'function': {...}, 'schema': {...}, 'type': 'function-before'}, 'type': 'function-before'}, 'type': 'model'}, 'type': 'function-after'}, 'type': 'function-after'}, 'type': 'function-after'}</dl>

<dl><dt><strong>__pydantic_custom_init__</strong> = True</dl>

<dl><dt><strong>__pydantic_decorators__</strong> = DecoratorInfos(validators={}, field_validators={...ecoratorInfo(mode='after'))}, computed_fields={})</dl>

<dl><dt><strong>__pydantic_fields__</strong> = {'additional_headers': FieldInfo(annotation=Union[Dict[str, str], NoneType], required=False, default=None), 'api_endpoint': FieldInfo(annotation=Union[str, NoneType], requi...default=None, alias='base_url', alias_priority=2), 'api_transport': FieldInfo(annotation=Union[str, NoneType], required=False, default=None), 'async_client': FieldInfo(annotation=Any, required=False, default=None, exclude=True), 'cache': FieldInfo(annotation=Union[BaseCache, bool, NoneType], required=False, default=None, exclude=True), 'cached_content': FieldInfo(annotation=Union[str, NoneType], required=False, default=None), 'callback_manager': FieldInfo(annotation=Union[BaseCallbackManager, ... manager to add to the run trace.', exclude=True), 'callbacks': FieldInfo(annotation=Union[list[BaseCallbackHand...ype], required=False, default=None, exclude=True), 'client': FieldInfo(annotation=Any, required=False, default=None, exclude=True), 'client_cert_source': FieldInfo(annotation=Union[Callable[list, Tuple[...bytes]], NoneType], required=False, default=None), ...}</dl>

<dl><dt><strong>__pydantic_generic_metadata__</strong> = {'args': (), 'origin': None, 'parameters': ()}</dl>

<dl><dt><strong>__pydantic_parent_namespace__</strong> = None</dl>

<dl><dt><strong>__pydantic_post_init__</strong> = None</dl>

<dl><dt><strong>__pydantic_serializer__</strong> = SchemaSerializer(serializer=Model(
    ModelSeri...  name: "ChatVertexAI",
    },
), definitions=[])</dl>

<dl><dt><strong>__pydantic_validator__</strong> = SchemaValidator(title="ChatVertexAI", validator=...se,
    },
), definitions=[], cache_strings=True)</dl>

<dl><dt><strong>__signature__</strong> = &lt;Signature (*args, model: str = '', proxy_model_...ring_raw_content: bool = True, **kwargs) -&gt; None&gt;</dl>

<dl><dt><strong>model_config</strong> = {'arbitrary_types_allowed': True, 'extra': 'allow', 'populate_by_name': True, 'protected_namespaces': ()}</dl>

<hr>
Methods inherited from <a href="langchain_google_vertexai.chat_models.html#ChatVertexAI">langchain_google_vertexai.chat_models.ChatVertexAI</a>:<br>
<dl><dt><a name="ChatVertexAI-bind_tools"><strong>bind_tools</strong></a>(self, tools: '_ToolsType', tool_config: 'Optional[_ToolConfigDict]' = None, *, tool_choice: 'Optional[Union[_ToolChoiceType, bool]]' = None, **kwargs: 'Any') -&gt; 'Runnable[LanguageModelInput, BaseMessage]'</dt><dd><tt>Bind&nbsp;tool-like&nbsp;objects&nbsp;to&nbsp;this&nbsp;chat&nbsp;model.<br>
&nbsp;<br>
Assumes&nbsp;model&nbsp;is&nbsp;compatible&nbsp;with&nbsp;Vertex&nbsp;tool-calling&nbsp;API.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tools:&nbsp;A&nbsp;list&nbsp;of&nbsp;tool&nbsp;definitions&nbsp;to&nbsp;bind&nbsp;to&nbsp;this&nbsp;chat&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;a&nbsp;pydantic&nbsp;model,&nbsp;callable,&nbsp;or&nbsp;BaseTool.&nbsp;Pydantic<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;models,&nbsp;callables,&nbsp;and&nbsp;BaseTools&nbsp;will&nbsp;be&nbsp;automatically&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;their&nbsp;schema&nbsp;dictionary&nbsp;representation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;**kwargs:&nbsp;Any&nbsp;additional&nbsp;parameters&nbsp;to&nbsp;pass&nbsp;to&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:class:`~langchain.runnable.Runnable`&nbsp;constructor.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-get_num_tokens"><strong>get_num_tokens</strong></a>(self, text: 'str') -&gt; 'int'</dt><dd><tt>Get&nbsp;the&nbsp;number&nbsp;of&nbsp;tokens&nbsp;present&nbsp;in&nbsp;the&nbsp;text.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-validate_environment"><strong>validate_environment</strong></a>(self) -&gt; 'Self'</dt><dd><tt>Validate&nbsp;that&nbsp;the&nbsp;python&nbsp;package&nbsp;exists&nbsp;in&nbsp;environment.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-validate_labels"><strong>validate_labels</strong></a>(self) -&gt; 'Self'</dt></dl>

<dl><dt><a name="ChatVertexAI-with_structured_output"><strong>with_structured_output</strong></a>(self, schema: 'Union[Dict, Type[BaseModel]]', *, include_raw: 'bool' = False, method: "Optional[Literal['json_mode']]" = None, **kwargs: 'Any') -&gt; 'Runnable[LanguageModelInput, Union[Dict, BaseModel]]'</dt><dd><tt>Model&nbsp;wrapper&nbsp;that&nbsp;returns&nbsp;outputs&nbsp;formatted&nbsp;to&nbsp;match&nbsp;the&nbsp;given&nbsp;schema.<br>
&nbsp;<br>
..&nbsp;versionchanged::&nbsp;1.1.0<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Return&nbsp;type&nbsp;corrected&nbsp;in&nbsp;version&nbsp;1.1.0.&nbsp;Previously&nbsp;if&nbsp;a&nbsp;dict&nbsp;schema<br>
&nbsp;&nbsp;&nbsp;&nbsp;was&nbsp;provided&nbsp;then&nbsp;the&nbsp;output&nbsp;had&nbsp;the&nbsp;form<br>
&nbsp;&nbsp;&nbsp;&nbsp;``[{"args":&nbsp;{},&nbsp;"name":&nbsp;"schema_name"}]``&nbsp;where&nbsp;the&nbsp;output&nbsp;was&nbsp;a&nbsp;list&nbsp;with<br>
&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;single&nbsp;dict&nbsp;and&nbsp;the&nbsp;"args"&nbsp;of&nbsp;the&nbsp;one&nbsp;dict&nbsp;corresponded&nbsp;to&nbsp;the&nbsp;schema.<br>
&nbsp;&nbsp;&nbsp;&nbsp;As&nbsp;of&nbsp;`1.1.0`&nbsp;this&nbsp;has&nbsp;been&nbsp;fixed&nbsp;so&nbsp;that&nbsp;the&nbsp;schema&nbsp;(the&nbsp;value<br>
&nbsp;&nbsp;&nbsp;&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;old&nbsp;"args"&nbsp;key)&nbsp;is&nbsp;returned&nbsp;directly.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;schema:&nbsp;The&nbsp;output&nbsp;schema&nbsp;as&nbsp;a&nbsp;dict&nbsp;or&nbsp;a&nbsp;Pydantic&nbsp;class.&nbsp;If&nbsp;a&nbsp;Pydantic&nbsp;class<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;then&nbsp;the&nbsp;model&nbsp;output&nbsp;will&nbsp;be&nbsp;an&nbsp;object&nbsp;of&nbsp;that&nbsp;class.&nbsp;If&nbsp;a&nbsp;dict&nbsp;then<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;model&nbsp;output&nbsp;will&nbsp;be&nbsp;a&nbsp;dict.&nbsp;With&nbsp;a&nbsp;Pydantic&nbsp;class&nbsp;the&nbsp;returned<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attributes&nbsp;will&nbsp;be&nbsp;validated,&nbsp;whereas&nbsp;with&nbsp;a&nbsp;dict&nbsp;they&nbsp;will&nbsp;not&nbsp;be.&nbsp;If<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`method`&nbsp;is&nbsp;"function_calling"&nbsp;and&nbsp;`schema`&nbsp;is&nbsp;a&nbsp;dict,&nbsp;then&nbsp;the&nbsp;dict<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;must&nbsp;match&nbsp;the&nbsp;OpenAI&nbsp;function-calling&nbsp;spec.<br>
&nbsp;&nbsp;&nbsp;&nbsp;include_raw:&nbsp;If&nbsp;False&nbsp;then&nbsp;only&nbsp;the&nbsp;parsed&nbsp;structured&nbsp;output&nbsp;is&nbsp;returned.&nbsp;If<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;an&nbsp;error&nbsp;occurs&nbsp;during&nbsp;model&nbsp;output&nbsp;parsing&nbsp;it&nbsp;will&nbsp;be&nbsp;raised.&nbsp;If&nbsp;True<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;then&nbsp;both&nbsp;the&nbsp;raw&nbsp;model&nbsp;response&nbsp;(a&nbsp;BaseMessage)&nbsp;and&nbsp;the&nbsp;parsed&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;response&nbsp;will&nbsp;be&nbsp;returned.&nbsp;If&nbsp;an&nbsp;error&nbsp;occurs&nbsp;during&nbsp;output&nbsp;parsing&nbsp;it<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will&nbsp;be&nbsp;caught&nbsp;and&nbsp;returned&nbsp;as&nbsp;well.&nbsp;The&nbsp;final&nbsp;output&nbsp;is&nbsp;always&nbsp;a&nbsp;dict<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;keys&nbsp;"raw",&nbsp;"parsed",&nbsp;and&nbsp;"parsing_error".<br>
&nbsp;&nbsp;&nbsp;&nbsp;method:&nbsp;If&nbsp;set&nbsp;to&nbsp;'json_schema'&nbsp;it&nbsp;will&nbsp;use&nbsp;controlled&nbsp;genetration&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;generate&nbsp;the&nbsp;response&nbsp;rather&nbsp;than&nbsp;function&nbsp;calling.&nbsp;Does&nbsp;not&nbsp;work&nbsp;with<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;schemas&nbsp;with&nbsp;references&nbsp;or&nbsp;Pydantic&nbsp;models&nbsp;with&nbsp;self-references.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;Runnable&nbsp;that&nbsp;takes&nbsp;any&nbsp;ChatModel&nbsp;input.&nbsp;If&nbsp;include_raw&nbsp;is&nbsp;True&nbsp;then&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict&nbsp;with&nbsp;keys&nbsp;â€”&nbsp;raw:&nbsp;BaseMessage,&nbsp;parsed:&nbsp;Optional[_DictOrPydantic],<br>
&nbsp;&nbsp;&nbsp;&nbsp;parsing_error:&nbsp;Optional[BaseException].&nbsp;If&nbsp;include_raw&nbsp;is&nbsp;False&nbsp;then&nbsp;just<br>
&nbsp;&nbsp;&nbsp;&nbsp;_DictOrPydantic&nbsp;is&nbsp;returned,&nbsp;where&nbsp;_DictOrPydantic&nbsp;depends&nbsp;on&nbsp;the&nbsp;schema.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;schema&nbsp;is&nbsp;a&nbsp;Pydantic&nbsp;class&nbsp;then&nbsp;_DictOrPydantic&nbsp;is&nbsp;the&nbsp;Pydantic&nbsp;class.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;schema&nbsp;is&nbsp;a&nbsp;dict&nbsp;then&nbsp;_DictOrPydantic&nbsp;is&nbsp;a&nbsp;dict.<br>
&nbsp;<br>
Example:&nbsp;Pydantic&nbsp;schema,&nbsp;exclude&nbsp;raw:<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;pydantic&nbsp;import&nbsp;BaseModel<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_google_vertexai&nbsp;import&nbsp;<a href="#ChatVertexAI">ChatVertexAI</a><br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;AnswerWithJustification(BaseModel):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'''An&nbsp;answer&nbsp;to&nbsp;the&nbsp;user&nbsp;question&nbsp;along&nbsp;with&nbsp;justification&nbsp;for&nbsp;the&nbsp;answer.'''<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;answer:&nbsp;str<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;justification:&nbsp;str<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;llm&nbsp;=&nbsp;<a href="#ChatVertexAI">ChatVertexAI</a>(model_name="gemini-pro",&nbsp;temperature=0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;structured_llm&nbsp;=&nbsp;llm.<a href="#ChatVertexAI-with_structured_output">with_structured_output</a>(AnswerWithJustification)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;structured_llm.<a href="#ChatVertexAI-invoke">invoke</a>("What&nbsp;weighs&nbsp;more&nbsp;a&nbsp;pound&nbsp;of&nbsp;bricks&nbsp;or&nbsp;a&nbsp;pound&nbsp;of&nbsp;feathers")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;-&gt;&nbsp;AnswerWithJustification(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;answer='They&nbsp;weigh&nbsp;the&nbsp;same.',&nbsp;justification='A&nbsp;pound&nbsp;is&nbsp;a&nbsp;pound.'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;)<br>
&nbsp;<br>
Example:&nbsp;Pydantic&nbsp;schema,&nbsp;include&nbsp;raw:<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;pydantic&nbsp;import&nbsp;BaseModel<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_google_vertexai&nbsp;import&nbsp;<a href="#ChatVertexAI">ChatVertexAI</a><br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;AnswerWithJustification(BaseModel):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'''An&nbsp;answer&nbsp;to&nbsp;the&nbsp;user&nbsp;question&nbsp;along&nbsp;with&nbsp;justification&nbsp;for&nbsp;the&nbsp;answer.'''<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;answer:&nbsp;str<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;justification:&nbsp;str<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;llm&nbsp;=&nbsp;<a href="#ChatVertexAI">ChatVertexAI</a>(model_name="gemini-pro",&nbsp;temperature=0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;structured_llm&nbsp;=&nbsp;llm.<a href="#ChatVertexAI-with_structured_output">with_structured_output</a>(AnswerWithJustification,&nbsp;include_raw=True)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;structured_llm.<a href="#ChatVertexAI-invoke">invoke</a>("What&nbsp;weighs&nbsp;more&nbsp;a&nbsp;pound&nbsp;of&nbsp;bricks&nbsp;or&nbsp;a&nbsp;pound&nbsp;of&nbsp;feathers")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;-&gt;&nbsp;{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'raw':&nbsp;AIMessage(content='',&nbsp;additional_kwargs={'tool_calls':&nbsp;[{'id':&nbsp;'call_Ao02pnFYXD6GN1yzc0uXPsvF',&nbsp;'function':&nbsp;{'arguments':&nbsp;'{"answer":"They&nbsp;weigh&nbsp;the&nbsp;same.","justification":"Both&nbsp;a&nbsp;pound&nbsp;of&nbsp;bricks&nbsp;and&nbsp;a&nbsp;pound&nbsp;of&nbsp;feathers&nbsp;weigh&nbsp;one&nbsp;pound.&nbsp;The&nbsp;weight&nbsp;is&nbsp;the&nbsp;same,&nbsp;but&nbsp;the&nbsp;volume&nbsp;or&nbsp;density&nbsp;of&nbsp;the&nbsp;objects&nbsp;may&nbsp;differ."}',&nbsp;'name':&nbsp;'AnswerWithJustification'},&nbsp;'type':&nbsp;'function'}]}),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'parsed':&nbsp;AnswerWithJustification(answer='They&nbsp;weigh&nbsp;the&nbsp;same.',&nbsp;justification='Both&nbsp;a&nbsp;pound&nbsp;of&nbsp;bricks&nbsp;and&nbsp;a&nbsp;pound&nbsp;of&nbsp;feathers&nbsp;weigh&nbsp;one&nbsp;pound.&nbsp;The&nbsp;weight&nbsp;is&nbsp;the&nbsp;same,&nbsp;but&nbsp;the&nbsp;volume&nbsp;or&nbsp;density&nbsp;of&nbsp;the&nbsp;objects&nbsp;may&nbsp;differ.'),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'parsing_error':&nbsp;None<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;}<br>
&nbsp;<br>
Example:&nbsp;Dict&nbsp;schema,&nbsp;exclude&nbsp;raw:<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;pydantic&nbsp;import&nbsp;BaseModel<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.utils.function_calling&nbsp;import&nbsp;convert_to_openai_function<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_google_vertexai&nbsp;import&nbsp;<a href="#ChatVertexAI">ChatVertexAI</a><br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;AnswerWithJustification(BaseModel):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'''An&nbsp;answer&nbsp;to&nbsp;the&nbsp;user&nbsp;question&nbsp;along&nbsp;with&nbsp;justification&nbsp;for&nbsp;the&nbsp;answer.'''<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;answer:&nbsp;str<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;justification:&nbsp;str<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dict_schema&nbsp;=&nbsp;convert_to_openai_function(AnswerWithJustification)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;llm&nbsp;=&nbsp;<a href="#ChatVertexAI">ChatVertexAI</a>(model_name="gemini-pro",&nbsp;temperature=0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;structured_llm&nbsp;=&nbsp;llm.<a href="#ChatVertexAI-with_structured_output">with_structured_output</a>(dict_schema)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;structured_llm.<a href="#ChatVertexAI-invoke">invoke</a>("What&nbsp;weighs&nbsp;more&nbsp;a&nbsp;pound&nbsp;of&nbsp;bricks&nbsp;or&nbsp;a&nbsp;pound&nbsp;of&nbsp;feathers")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;-&gt;&nbsp;{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'answer':&nbsp;'They&nbsp;weigh&nbsp;the&nbsp;same',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'justification':&nbsp;'Both&nbsp;a&nbsp;pound&nbsp;of&nbsp;bricks&nbsp;and&nbsp;a&nbsp;pound&nbsp;of&nbsp;feathers&nbsp;weigh&nbsp;one&nbsp;pound.&nbsp;The&nbsp;weight&nbsp;is&nbsp;the&nbsp;same,&nbsp;but&nbsp;the&nbsp;volume&nbsp;and&nbsp;density&nbsp;of&nbsp;the&nbsp;two&nbsp;substances&nbsp;differ.'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;}</tt></dd></dl>

<hr>
Class methods inherited from <a href="langchain_google_vertexai.chat_models.html#ChatVertexAI">langchain_google_vertexai.chat_models.ChatVertexAI</a>:<br>
<dl><dt><a name="ChatVertexAI-get_lc_namespace"><strong>get_lc_namespace</strong></a>() -&gt; 'List[str]'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Get&nbsp;the&nbsp;namespace&nbsp;of&nbsp;the&nbsp;langchain&nbsp;object.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-is_lc_serializable"><strong>is_lc_serializable</strong></a>() -&gt; 'bool'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Is&nbsp;this&nbsp;class&nbsp;serializable?<br>
&nbsp;<br>
By&nbsp;design,&nbsp;even&nbsp;if&nbsp;a&nbsp;class&nbsp;inherits&nbsp;from&nbsp;Serializable,&nbsp;it&nbsp;is&nbsp;not&nbsp;serializable&nbsp;by<br>
default.&nbsp;This&nbsp;is&nbsp;to&nbsp;prevent&nbsp;accidental&nbsp;serialization&nbsp;of&nbsp;objects&nbsp;that&nbsp;should&nbsp;not<br>
be&nbsp;serialized.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;the&nbsp;class&nbsp;is&nbsp;serializable.&nbsp;Default&nbsp;is&nbsp;False.</tt></dd></dl>

<hr>
Data and other attributes inherited from <a href="langchain_google_vertexai.chat_models.html#ChatVertexAI">langchain_google_vertexai.chat_models.ChatVertexAI</a>:<br>
<dl><dt><strong>__annotations__</strong> = {'cached_content': 'Optional[str]', 'convert_system_message_to_human': 'bool', 'examples': 'Optional[List[BaseMessage]]', 'labels': 'Optional[Dict[str, str]]', 'logprobs': 'Union[bool, int]', 'model_name': 'str', 'perform_literal_eval_on_string_raw_content': 'bool', 'response_mime_type': 'Optional[str]', 'response_schema': 'Optional[Dict[str, Any]]'}</dl>

<hr>
Readonly properties inherited from <a href="langchain_google_vertexai._base.html#_VertexAICommon">langchain_google_vertexai._base._VertexAICommon</a>:<br>
<dl><dt><strong>max_tokens</strong></dt>
</dl>
<hr>
Methods inherited from <a href="langchain_google_vertexai._base.html#_VertexAIBase">langchain_google_vertexai._base._VertexAIBase</a>:<br>
<dl><dt><a name="ChatVertexAI-validate_project"><strong>validate_project</strong></a>(self) -&gt; 'Any'</dt></dl>

<hr>
Data descriptors inherited from <a href="langchain_google_vertexai._base.html#_VertexAIBase">langchain_google_vertexai._base._VertexAIBase</a>:<br>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="langchain_google_vertexai._base.html#_VertexAIBase">langchain_google_vertexai._base._VertexAIBase</a>:<br>
<dl><dt><strong>task_executor</strong> = FieldInfo(annotation=NoneType, required=False, default=None, exclude=True)</dl>

<hr>
Methods inherited from <a href="langchain_core.language_models.chat_models.html#BaseChatModel">langchain_core.language_models.chat_models.BaseChatModel</a>:<br>
<dl><dt><a name="ChatVertexAI-__call__"><strong>__call__</strong></a>(self, messages: 'list[BaseMessage]', stop: 'Optional[list[str]]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -&gt; 'BaseMessage'</dt><dd><tt>..&nbsp;deprecated::&nbsp;0.1.7&nbsp;Use&nbsp;:meth:`~invoke`&nbsp;instead.&nbsp;It&nbsp;will&nbsp;not&nbsp;be&nbsp;removed&nbsp;until&nbsp;langchain-core==1.0.</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-agenerate"><strong>agenerate</strong></a>(self, messages: 'list[list[BaseMessage]]', stop: 'Optional[list[str]]' = None, callbacks: 'Callbacks' = None, *, tags: 'Optional[list[str]]' = None, metadata: 'Optional[dict[str, Any]]' = None, run_name: 'Optional[str]' = None, run_id: 'Optional[uuid.UUID]' = None, **kwargs: 'Any') -&gt; 'LLMResult'</dt><dd><tt>Asynchronously&nbsp;pass&nbsp;a&nbsp;sequence&nbsp;of&nbsp;prompts&nbsp;to&nbsp;a&nbsp;model&nbsp;and&nbsp;return&nbsp;generations.<br>
&nbsp;<br>
This&nbsp;method&nbsp;should&nbsp;make&nbsp;use&nbsp;of&nbsp;batched&nbsp;calls&nbsp;for&nbsp;models&nbsp;that&nbsp;expose&nbsp;a&nbsp;batched<br>
API.<br>
&nbsp;<br>
Use&nbsp;this&nbsp;method&nbsp;when&nbsp;you&nbsp;want&nbsp;to:<br>
&nbsp;&nbsp;&nbsp;&nbsp;1.&nbsp;take&nbsp;advantage&nbsp;of&nbsp;batched&nbsp;calls,<br>
&nbsp;&nbsp;&nbsp;&nbsp;2.&nbsp;need&nbsp;more&nbsp;output&nbsp;from&nbsp;the&nbsp;model&nbsp;than&nbsp;just&nbsp;the&nbsp;top&nbsp;generated&nbsp;value,<br>
&nbsp;&nbsp;&nbsp;&nbsp;3.&nbsp;are&nbsp;building&nbsp;chains&nbsp;that&nbsp;are&nbsp;agnostic&nbsp;to&nbsp;the&nbsp;underlying&nbsp;language&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type&nbsp;(e.g.,&nbsp;pure&nbsp;text&nbsp;completion&nbsp;models&nbsp;vs&nbsp;chat&nbsp;models).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;messages:&nbsp;List&nbsp;of&nbsp;list&nbsp;of&nbsp;messages.<br>
&nbsp;&nbsp;&nbsp;&nbsp;stop:&nbsp;Stop&nbsp;words&nbsp;to&nbsp;use&nbsp;when&nbsp;generating.&nbsp;Model&nbsp;output&nbsp;is&nbsp;cut&nbsp;off&nbsp;at&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;first&nbsp;occurrence&nbsp;of&nbsp;any&nbsp;of&nbsp;these&nbsp;substrings.<br>
&nbsp;&nbsp;&nbsp;&nbsp;callbacks:&nbsp;Callbacks&nbsp;to&nbsp;pass&nbsp;through.&nbsp;Used&nbsp;for&nbsp;executing&nbsp;additional<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;functionality,&nbsp;such&nbsp;as&nbsp;logging&nbsp;or&nbsp;streaming,&nbsp;throughout&nbsp;generation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;**kwargs:&nbsp;Arbitrary&nbsp;additional&nbsp;keyword&nbsp;arguments.&nbsp;These&nbsp;are&nbsp;usually&nbsp;passed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;the&nbsp;model&nbsp;provider&nbsp;API&nbsp;call.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;An&nbsp;LLMResult,&nbsp;which&nbsp;contains&nbsp;a&nbsp;list&nbsp;of&nbsp;candidate&nbsp;Generations&nbsp;for&nbsp;each&nbsp;input<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt&nbsp;and&nbsp;additional&nbsp;model&nbsp;provider-specific&nbsp;output.</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-agenerate_prompt"><strong>agenerate_prompt</strong></a>(self, prompts: 'list[PromptValue]', stop: 'Optional[list[str]]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -&gt; 'LLMResult'</dt><dd><tt>Asynchronously&nbsp;pass&nbsp;a&nbsp;sequence&nbsp;of&nbsp;prompts&nbsp;and&nbsp;return&nbsp;model&nbsp;generations.<br>
&nbsp;<br>
This&nbsp;method&nbsp;should&nbsp;make&nbsp;use&nbsp;of&nbsp;batched&nbsp;calls&nbsp;for&nbsp;models&nbsp;that&nbsp;expose&nbsp;a&nbsp;batched<br>
API.<br>
&nbsp;<br>
Use&nbsp;this&nbsp;method&nbsp;when&nbsp;you&nbsp;want&nbsp;to:<br>
&nbsp;&nbsp;&nbsp;&nbsp;1.&nbsp;take&nbsp;advantage&nbsp;of&nbsp;batched&nbsp;calls,<br>
&nbsp;&nbsp;&nbsp;&nbsp;2.&nbsp;need&nbsp;more&nbsp;output&nbsp;from&nbsp;the&nbsp;model&nbsp;than&nbsp;just&nbsp;the&nbsp;top&nbsp;generated&nbsp;value,<br>
&nbsp;&nbsp;&nbsp;&nbsp;3.&nbsp;are&nbsp;building&nbsp;chains&nbsp;that&nbsp;are&nbsp;agnostic&nbsp;to&nbsp;the&nbsp;underlying&nbsp;language&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type&nbsp;(e.g.,&nbsp;pure&nbsp;text&nbsp;completion&nbsp;models&nbsp;vs&nbsp;chat&nbsp;models).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompts:&nbsp;List&nbsp;of&nbsp;PromptValues.&nbsp;A&nbsp;PromptValue&nbsp;is&nbsp;an&nbsp;object&nbsp;that&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;converted&nbsp;to&nbsp;match&nbsp;the&nbsp;format&nbsp;of&nbsp;any&nbsp;language&nbsp;model&nbsp;(string&nbsp;for&nbsp;pure<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;text&nbsp;generation&nbsp;models&nbsp;and&nbsp;BaseMessages&nbsp;for&nbsp;chat&nbsp;models).<br>
&nbsp;&nbsp;&nbsp;&nbsp;stop:&nbsp;Stop&nbsp;words&nbsp;to&nbsp;use&nbsp;when&nbsp;generating.&nbsp;Model&nbsp;output&nbsp;is&nbsp;cut&nbsp;off&nbsp;at&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;first&nbsp;occurrence&nbsp;of&nbsp;any&nbsp;of&nbsp;these&nbsp;substrings.<br>
&nbsp;&nbsp;&nbsp;&nbsp;callbacks:&nbsp;Callbacks&nbsp;to&nbsp;pass&nbsp;through.&nbsp;Used&nbsp;for&nbsp;executing&nbsp;additional<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;functionality,&nbsp;such&nbsp;as&nbsp;logging&nbsp;or&nbsp;streaming,&nbsp;throughout&nbsp;generation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;**kwargs:&nbsp;Arbitrary&nbsp;additional&nbsp;keyword&nbsp;arguments.&nbsp;These&nbsp;are&nbsp;usually&nbsp;passed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;the&nbsp;model&nbsp;provider&nbsp;API&nbsp;call.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;An&nbsp;LLMResult,&nbsp;which&nbsp;contains&nbsp;a&nbsp;list&nbsp;of&nbsp;candidate&nbsp;Generations&nbsp;for&nbsp;each&nbsp;input<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt&nbsp;and&nbsp;additional&nbsp;model&nbsp;provider-specific&nbsp;output.</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-ainvoke"><strong>ainvoke</strong></a>(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -&gt; 'BaseMessage'</dt><dd><tt>Default&nbsp;implementation&nbsp;of&nbsp;ainvoke,&nbsp;calls&nbsp;invoke&nbsp;from&nbsp;a&nbsp;thread.<br>
&nbsp;<br>
The&nbsp;default&nbsp;implementation&nbsp;allows&nbsp;usage&nbsp;of&nbsp;async&nbsp;code&nbsp;even&nbsp;if<br>
the&nbsp;Runnable&nbsp;did&nbsp;not&nbsp;implement&nbsp;a&nbsp;native&nbsp;async&nbsp;version&nbsp;of&nbsp;invoke.<br>
&nbsp;<br>
Subclasses&nbsp;should&nbsp;override&nbsp;this&nbsp;method&nbsp;if&nbsp;they&nbsp;can&nbsp;run&nbsp;asynchronously.</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-apredict"><strong>apredict</strong></a>(self, text: 'str', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -&gt; 'str'</dt><dd><tt>..&nbsp;deprecated::&nbsp;0.1.7&nbsp;Use&nbsp;:meth:`~ainvoke`&nbsp;instead.&nbsp;It&nbsp;will&nbsp;not&nbsp;be&nbsp;removed&nbsp;until&nbsp;langchain-core==1.0.</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-apredict_messages"><strong>apredict_messages</strong></a>(self, messages: 'list[BaseMessage]', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -&gt; 'BaseMessage'</dt><dd><tt>..&nbsp;deprecated::&nbsp;0.1.7&nbsp;Use&nbsp;:meth:`~ainvoke`&nbsp;instead.&nbsp;It&nbsp;will&nbsp;not&nbsp;be&nbsp;removed&nbsp;until&nbsp;langchain-core==1.0.</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-astream"><strong>astream</strong></a>(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -&gt; 'AsyncIterator[BaseMessageChunk]'</dt><dd><tt>Default&nbsp;implementation&nbsp;of&nbsp;astream,&nbsp;which&nbsp;calls&nbsp;ainvoke.<br>
Subclasses&nbsp;should&nbsp;override&nbsp;this&nbsp;method&nbsp;if&nbsp;they&nbsp;support&nbsp;streaming&nbsp;output.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input:&nbsp;The&nbsp;input&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;The&nbsp;config&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;Runnable.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs:&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;output&nbsp;of&nbsp;the&nbsp;Runnable.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-call_as_llm"><strong>call_as_llm</strong></a>(self, message: 'str', stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -&gt; 'str'</dt><dd><tt>..&nbsp;deprecated::&nbsp;0.1.7&nbsp;Use&nbsp;:meth:`~invoke`&nbsp;instead.&nbsp;It&nbsp;will&nbsp;not&nbsp;be&nbsp;removed&nbsp;until&nbsp;langchain-core==1.0.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-dict"><strong>dict</strong></a>(self, **kwargs: 'Any') -&gt; 'dict'</dt><dd><tt>Return&nbsp;a&nbsp;dictionary&nbsp;of&nbsp;the&nbsp;LLM.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-generate"><strong>generate</strong></a>(self, messages: 'list[list[BaseMessage]]', stop: 'Optional[list[str]]' = None, callbacks: 'Callbacks' = None, *, tags: 'Optional[list[str]]' = None, metadata: 'Optional[dict[str, Any]]' = None, run_name: 'Optional[str]' = None, run_id: 'Optional[uuid.UUID]' = None, **kwargs: 'Any') -&gt; 'LLMResult'</dt><dd><tt>Pass&nbsp;a&nbsp;sequence&nbsp;of&nbsp;prompts&nbsp;to&nbsp;the&nbsp;model&nbsp;and&nbsp;return&nbsp;model&nbsp;generations.<br>
&nbsp;<br>
This&nbsp;method&nbsp;should&nbsp;make&nbsp;use&nbsp;of&nbsp;batched&nbsp;calls&nbsp;for&nbsp;models&nbsp;that&nbsp;expose&nbsp;a&nbsp;batched<br>
API.<br>
&nbsp;<br>
Use&nbsp;this&nbsp;method&nbsp;when&nbsp;you&nbsp;want&nbsp;to:<br>
&nbsp;&nbsp;&nbsp;&nbsp;1.&nbsp;take&nbsp;advantage&nbsp;of&nbsp;batched&nbsp;calls,<br>
&nbsp;&nbsp;&nbsp;&nbsp;2.&nbsp;need&nbsp;more&nbsp;output&nbsp;from&nbsp;the&nbsp;model&nbsp;than&nbsp;just&nbsp;the&nbsp;top&nbsp;generated&nbsp;value,<br>
&nbsp;&nbsp;&nbsp;&nbsp;3.&nbsp;are&nbsp;building&nbsp;chains&nbsp;that&nbsp;are&nbsp;agnostic&nbsp;to&nbsp;the&nbsp;underlying&nbsp;language&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type&nbsp;(e.g.,&nbsp;pure&nbsp;text&nbsp;completion&nbsp;models&nbsp;vs&nbsp;chat&nbsp;models).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;messages:&nbsp;List&nbsp;of&nbsp;list&nbsp;of&nbsp;messages.<br>
&nbsp;&nbsp;&nbsp;&nbsp;stop:&nbsp;Stop&nbsp;words&nbsp;to&nbsp;use&nbsp;when&nbsp;generating.&nbsp;Model&nbsp;output&nbsp;is&nbsp;cut&nbsp;off&nbsp;at&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;first&nbsp;occurrence&nbsp;of&nbsp;any&nbsp;of&nbsp;these&nbsp;substrings.<br>
&nbsp;&nbsp;&nbsp;&nbsp;callbacks:&nbsp;Callbacks&nbsp;to&nbsp;pass&nbsp;through.&nbsp;Used&nbsp;for&nbsp;executing&nbsp;additional<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;functionality,&nbsp;such&nbsp;as&nbsp;logging&nbsp;or&nbsp;streaming,&nbsp;throughout&nbsp;generation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;**kwargs:&nbsp;Arbitrary&nbsp;additional&nbsp;keyword&nbsp;arguments.&nbsp;These&nbsp;are&nbsp;usually&nbsp;passed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;the&nbsp;model&nbsp;provider&nbsp;API&nbsp;call.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;An&nbsp;LLMResult,&nbsp;which&nbsp;contains&nbsp;a&nbsp;list&nbsp;of&nbsp;candidate&nbsp;Generations&nbsp;for&nbsp;each&nbsp;input<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt&nbsp;and&nbsp;additional&nbsp;model&nbsp;provider-specific&nbsp;output.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-generate_prompt"><strong>generate_prompt</strong></a>(self, prompts: 'list[PromptValue]', stop: 'Optional[list[str]]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -&gt; 'LLMResult'</dt><dd><tt>Pass&nbsp;a&nbsp;sequence&nbsp;of&nbsp;prompts&nbsp;to&nbsp;the&nbsp;model&nbsp;and&nbsp;return&nbsp;model&nbsp;generations.<br>
&nbsp;<br>
This&nbsp;method&nbsp;should&nbsp;make&nbsp;use&nbsp;of&nbsp;batched&nbsp;calls&nbsp;for&nbsp;models&nbsp;that&nbsp;expose&nbsp;a&nbsp;batched<br>
API.<br>
&nbsp;<br>
Use&nbsp;this&nbsp;method&nbsp;when&nbsp;you&nbsp;want&nbsp;to:<br>
&nbsp;&nbsp;&nbsp;&nbsp;1.&nbsp;take&nbsp;advantage&nbsp;of&nbsp;batched&nbsp;calls,<br>
&nbsp;&nbsp;&nbsp;&nbsp;2.&nbsp;need&nbsp;more&nbsp;output&nbsp;from&nbsp;the&nbsp;model&nbsp;than&nbsp;just&nbsp;the&nbsp;top&nbsp;generated&nbsp;value,<br>
&nbsp;&nbsp;&nbsp;&nbsp;3.&nbsp;are&nbsp;building&nbsp;chains&nbsp;that&nbsp;are&nbsp;agnostic&nbsp;to&nbsp;the&nbsp;underlying&nbsp;language&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type&nbsp;(e.g.,&nbsp;pure&nbsp;text&nbsp;completion&nbsp;models&nbsp;vs&nbsp;chat&nbsp;models).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompts:&nbsp;List&nbsp;of&nbsp;PromptValues.&nbsp;A&nbsp;PromptValue&nbsp;is&nbsp;an&nbsp;object&nbsp;that&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;converted&nbsp;to&nbsp;match&nbsp;the&nbsp;format&nbsp;of&nbsp;any&nbsp;language&nbsp;model&nbsp;(string&nbsp;for&nbsp;pure<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;text&nbsp;generation&nbsp;models&nbsp;and&nbsp;BaseMessages&nbsp;for&nbsp;chat&nbsp;models).<br>
&nbsp;&nbsp;&nbsp;&nbsp;stop:&nbsp;Stop&nbsp;words&nbsp;to&nbsp;use&nbsp;when&nbsp;generating.&nbsp;Model&nbsp;output&nbsp;is&nbsp;cut&nbsp;off&nbsp;at&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;first&nbsp;occurrence&nbsp;of&nbsp;any&nbsp;of&nbsp;these&nbsp;substrings.<br>
&nbsp;&nbsp;&nbsp;&nbsp;callbacks:&nbsp;Callbacks&nbsp;to&nbsp;pass&nbsp;through.&nbsp;Used&nbsp;for&nbsp;executing&nbsp;additional<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;functionality,&nbsp;such&nbsp;as&nbsp;logging&nbsp;or&nbsp;streaming,&nbsp;throughout&nbsp;generation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;**kwargs:&nbsp;Arbitrary&nbsp;additional&nbsp;keyword&nbsp;arguments.&nbsp;These&nbsp;are&nbsp;usually&nbsp;passed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;the&nbsp;model&nbsp;provider&nbsp;API&nbsp;call.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;An&nbsp;LLMResult,&nbsp;which&nbsp;contains&nbsp;a&nbsp;list&nbsp;of&nbsp;candidate&nbsp;Generations&nbsp;for&nbsp;each&nbsp;input<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt&nbsp;and&nbsp;additional&nbsp;model&nbsp;provider-specific&nbsp;output.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-invoke"><strong>invoke</strong></a>(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -&gt; 'BaseMessage'</dt><dd><tt>Transform&nbsp;a&nbsp;single&nbsp;input&nbsp;into&nbsp;an&nbsp;output.&nbsp;Override&nbsp;to&nbsp;implement.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input:&nbsp;The&nbsp;input&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;A&nbsp;config&nbsp;to&nbsp;use&nbsp;when&nbsp;invoking&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;config&nbsp;supports&nbsp;standard&nbsp;keys&nbsp;like&nbsp;'tags',&nbsp;'metadata'&nbsp;for&nbsp;tracing<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;purposes,&nbsp;'max_concurrency'&nbsp;for&nbsp;controlling&nbsp;how&nbsp;much&nbsp;work&nbsp;to&nbsp;do<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;parallel,&nbsp;and&nbsp;other&nbsp;keys.&nbsp;Please&nbsp;refer&nbsp;to&nbsp;the&nbsp;RunnableConfig<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;more&nbsp;details.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;output&nbsp;of&nbsp;the&nbsp;Runnable.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-predict"><strong>predict</strong></a>(self, text: 'str', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -&gt; 'str'</dt><dd><tt>..&nbsp;deprecated::&nbsp;0.1.7&nbsp;Use&nbsp;:meth:`~invoke`&nbsp;instead.&nbsp;It&nbsp;will&nbsp;not&nbsp;be&nbsp;removed&nbsp;until&nbsp;langchain-core==1.0.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-predict_messages"><strong>predict_messages</strong></a>(self, messages: 'list[BaseMessage]', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -&gt; 'BaseMessage'</dt><dd><tt>..&nbsp;deprecated::&nbsp;0.1.7&nbsp;Use&nbsp;:meth:`~invoke`&nbsp;instead.&nbsp;It&nbsp;will&nbsp;not&nbsp;be&nbsp;removed&nbsp;until&nbsp;langchain-core==1.0.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-stream"><strong>stream</strong></a>(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -&gt; 'Iterator[BaseMessageChunk]'</dt><dd><tt>Default&nbsp;implementation&nbsp;of&nbsp;stream,&nbsp;which&nbsp;calls&nbsp;invoke.<br>
Subclasses&nbsp;should&nbsp;override&nbsp;this&nbsp;method&nbsp;if&nbsp;they&nbsp;support&nbsp;streaming&nbsp;output.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input:&nbsp;The&nbsp;input&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;The&nbsp;config&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;Runnable.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs:&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;output&nbsp;of&nbsp;the&nbsp;Runnable.</tt></dd></dl>

<hr>
Class methods inherited from <a href="langchain_core.language_models.chat_models.html#BaseChatModel">langchain_core.language_models.chat_models.BaseChatModel</a>:<br>
<dl><dt><a name="ChatVertexAI-raise_deprecation"><strong>raise_deprecation</strong></a>(values: 'dict') -&gt; 'Any'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Raise&nbsp;deprecation&nbsp;warning&nbsp;if&nbsp;callback_manager&nbsp;is&nbsp;used.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;values&nbsp;(Dict):&nbsp;Values&nbsp;to&nbsp;validate.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Dict:&nbsp;Validated&nbsp;values.<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;DeprecationWarning:&nbsp;If&nbsp;callback_manager&nbsp;is&nbsp;used.</tt></dd></dl>

<hr>
Readonly properties inherited from <a href="langchain_core.language_models.chat_models.html#BaseChatModel">langchain_core.language_models.chat_models.BaseChatModel</a>:<br>
<dl><dt><strong>OutputType</strong></dt>
<dd><tt>Get&nbsp;the&nbsp;output&nbsp;type&nbsp;for&nbsp;this&nbsp;runnable.</tt></dd>
</dl>
<hr>
Methods inherited from <a href="langchain_core.language_models.base.html#BaseLanguageModel">langchain_core.language_models.base.BaseLanguageModel</a>:<br>
<dl><dt><a name="ChatVertexAI-get_num_tokens_from_messages"><strong>get_num_tokens_from_messages</strong></a>(self, messages: 'list[BaseMessage]', tools: 'Optional[Sequence]' = None) -&gt; 'int'</dt><dd><tt>Get&nbsp;the&nbsp;number&nbsp;of&nbsp;tokens&nbsp;in&nbsp;the&nbsp;messages.<br>
&nbsp;<br>
Useful&nbsp;for&nbsp;checking&nbsp;if&nbsp;an&nbsp;input&nbsp;fits&nbsp;in&nbsp;a&nbsp;model's&nbsp;context&nbsp;window.<br>
&nbsp;<br>
**Note**:&nbsp;the&nbsp;base&nbsp;implementation&nbsp;of&nbsp;get_num_tokens_from_messages&nbsp;ignores<br>
tool&nbsp;schemas.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;messages:&nbsp;The&nbsp;message&nbsp;inputs&nbsp;to&nbsp;tokenize.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tools:&nbsp;If&nbsp;provided,&nbsp;sequence&nbsp;of&nbsp;dict,&nbsp;BaseModel,&nbsp;function,&nbsp;or&nbsp;BaseTools<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;be&nbsp;converted&nbsp;to&nbsp;tool&nbsp;schemas.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;sum&nbsp;of&nbsp;the&nbsp;number&nbsp;of&nbsp;tokens&nbsp;across&nbsp;the&nbsp;messages.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-get_token_ids"><strong>get_token_ids</strong></a>(self, text: 'str') -&gt; 'list[int]'</dt><dd><tt>Return&nbsp;the&nbsp;ordered&nbsp;ids&nbsp;of&nbsp;the&nbsp;tokens&nbsp;in&nbsp;a&nbsp;text.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;text:&nbsp;The&nbsp;string&nbsp;input&nbsp;to&nbsp;tokenize.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;ids&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;tokens&nbsp;in&nbsp;the&nbsp;text,&nbsp;in&nbsp;order&nbsp;they&nbsp;occur<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;the&nbsp;text.</tt></dd></dl>

<hr>
Class methods inherited from <a href="langchain_core.language_models.base.html#BaseLanguageModel">langchain_core.language_models.base.BaseLanguageModel</a>:<br>
<dl><dt><a name="ChatVertexAI-set_verbose"><strong>set_verbose</strong></a>(verbose: 'Optional[bool]') -&gt; 'bool'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>If&nbsp;verbose&nbsp;is&nbsp;None,&nbsp;set&nbsp;it.<br>
&nbsp;<br>
This&nbsp;allows&nbsp;users&nbsp;to&nbsp;pass&nbsp;in&nbsp;None&nbsp;as&nbsp;verbose&nbsp;to&nbsp;access&nbsp;the&nbsp;global&nbsp;setting.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;verbose:&nbsp;The&nbsp;verbosity&nbsp;setting&nbsp;to&nbsp;use.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;verbosity&nbsp;setting&nbsp;to&nbsp;use.</tt></dd></dl>

<hr>
Readonly properties inherited from <a href="langchain_core.language_models.base.html#BaseLanguageModel">langchain_core.language_models.base.BaseLanguageModel</a>:<br>
<dl><dt><strong>InputType</strong></dt>
<dd><tt>Get&nbsp;the&nbsp;input&nbsp;type&nbsp;for&nbsp;this&nbsp;runnable.</tt></dd>
</dl>
<hr>
Methods inherited from <a href="langchain_core.runnables.base.html#RunnableSerializable">langchain_core.runnables.base.RunnableSerializable</a>:<br>
<dl><dt><a name="ChatVertexAI-configurable_alternatives"><strong>configurable_alternatives</strong></a>(self, which: 'ConfigurableField', *, default_key: 'str' = 'default', prefix_keys: 'bool' = False, **kwargs: 'Union[Runnable[Input, Output], Callable[[], Runnable[Input, Output]]]') -&gt; 'RunnableSerializable[Input, Output]'</dt><dd><tt>Configure&nbsp;alternatives&nbsp;for&nbsp;Runnables&nbsp;that&nbsp;can&nbsp;be&nbsp;set&nbsp;at&nbsp;runtime.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;which:&nbsp;The&nbsp;ConfigurableField&nbsp;instance&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;to&nbsp;select&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alternative.<br>
&nbsp;&nbsp;&nbsp;&nbsp;default_key:&nbsp;The&nbsp;default&nbsp;key&nbsp;to&nbsp;use&nbsp;if&nbsp;no&nbsp;alternative&nbsp;is&nbsp;selected.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;"default".<br>
&nbsp;&nbsp;&nbsp;&nbsp;prefix_keys:&nbsp;Whether&nbsp;to&nbsp;prefix&nbsp;the&nbsp;keys&nbsp;with&nbsp;the&nbsp;ConfigurableField&nbsp;id.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;**kwargs:&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;keys&nbsp;to&nbsp;Runnable&nbsp;instances&nbsp;or&nbsp;callables&nbsp;that<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;Runnable&nbsp;instances.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;with&nbsp;the&nbsp;alternatives&nbsp;configured.<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_anthropic&nbsp;import&nbsp;ChatAnthropic<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables.utils&nbsp;import&nbsp;ConfigurableField<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_openai&nbsp;import&nbsp;ChatOpenAI<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;model&nbsp;=&nbsp;ChatAnthropic(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model_name="claude-3-sonnet-20240229"<br>
&nbsp;&nbsp;&nbsp;&nbsp;).<a href="#ChatVertexAI-configurable_alternatives">configurable_alternatives</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ConfigurableField(id="llm"),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;default_key="anthropic",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;openai=ChatOpenAI()<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;uses&nbsp;the&nbsp;default&nbsp;model&nbsp;ChatAnthropic<br>
&nbsp;&nbsp;&nbsp;&nbsp;print(model.<a href="#ChatVertexAI-invoke">invoke</a>("which&nbsp;organization&nbsp;created&nbsp;you?").content)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;uses&nbsp;ChatOpenAI<br>
&nbsp;&nbsp;&nbsp;&nbsp;print(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.<a href="#ChatVertexAI-with_config">with_config</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;configurable={"llm":&nbsp;"openai"}<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;).<a href="#ChatVertexAI-invoke">invoke</a>("which&nbsp;organization&nbsp;created&nbsp;you?").content<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-configurable_fields"><strong>configurable_fields</strong></a>(self, **kwargs: 'AnyConfigurableField') -&gt; 'RunnableSerializable[Input, Output]'</dt><dd><tt>Configure&nbsp;particular&nbsp;Runnable&nbsp;fields&nbsp;at&nbsp;runtime.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;**kwargs:&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;ConfigurableField&nbsp;instances&nbsp;to&nbsp;configure.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;with&nbsp;the&nbsp;fields&nbsp;configured.<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;ConfigurableField<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_openai&nbsp;import&nbsp;ChatOpenAI<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;model&nbsp;=&nbsp;ChatOpenAI(max_tokens=20).<a href="#ChatVertexAI-configurable_fields">configurable_fields</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_tokens=ConfigurableField(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id="output_token_number",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name="Max&nbsp;tokens&nbsp;in&nbsp;the&nbsp;output",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description="The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;tokens&nbsp;in&nbsp;the&nbsp;output",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;max_tokens&nbsp;=&nbsp;20<br>
&nbsp;&nbsp;&nbsp;&nbsp;print(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"max_tokens_20:&nbsp;",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.<a href="#ChatVertexAI-invoke">invoke</a>("tell&nbsp;me&nbsp;something&nbsp;about&nbsp;chess").content<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;max_tokens&nbsp;=&nbsp;200<br>
&nbsp;&nbsp;&nbsp;&nbsp;print("max_tokens_200:&nbsp;",&nbsp;model.<a href="#ChatVertexAI-with_config">with_config</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;configurable={"output_token_number":&nbsp;200}<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;).<a href="#ChatVertexAI-invoke">invoke</a>("tell&nbsp;me&nbsp;something&nbsp;about&nbsp;chess").content<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-to_json"><strong>to_json</strong></a>(self) -&gt; 'Union[SerializedConstructor, SerializedNotImplemented]'</dt><dd><tt>Serialize&nbsp;the&nbsp;Runnable&nbsp;to&nbsp;JSON.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;JSON-serializable&nbsp;representation&nbsp;of&nbsp;the&nbsp;Runnable.</tt></dd></dl>

<hr>
Data and other attributes inherited from <a href="langchain_core.runnables.base.html#RunnableSerializable">langchain_core.runnables.base.RunnableSerializable</a>:<br>
<dl><dt><strong>__orig_bases__</strong> = (&lt;class 'langchain_core.load.serializable.Serializable'&gt;, langchain_core.runnables.base.Runnable[-Input, +Output])</dl>

<hr>
Methods inherited from <a href="langchain_core.load.serializable.html#Serializable">langchain_core.load.serializable.Serializable</a>:<br>
<dl><dt><a name="ChatVertexAI-__repr_args__"><strong>__repr_args__</strong></a>(self) -&gt; Any</dt></dl>

<dl><dt><a name="ChatVertexAI-to_json_not_implemented"><strong>to_json_not_implemented</strong></a>(self) -&gt; langchain_core.load.serializable.SerializedNotImplemented</dt></dl>

<hr>
Class methods inherited from <a href="langchain_core.load.serializable.html#Serializable">langchain_core.load.serializable.Serializable</a>:<br>
<dl><dt><a name="ChatVertexAI-lc_id"><strong>lc_id</strong></a>() -&gt; list[str]<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>A&nbsp;unique&nbsp;identifier&nbsp;for&nbsp;this&nbsp;class&nbsp;for&nbsp;serialization&nbsp;purposes.<br>
&nbsp;<br>
The&nbsp;unique&nbsp;identifier&nbsp;is&nbsp;a&nbsp;list&nbsp;of&nbsp;strings&nbsp;that&nbsp;describes&nbsp;the&nbsp;path<br>
to&nbsp;the&nbsp;object.<br>
For&nbsp;example,&nbsp;for&nbsp;the&nbsp;class&nbsp;`langchain.llms.openai.OpenAI`,&nbsp;the&nbsp;id&nbsp;is<br>
["langchain",&nbsp;"llms",&nbsp;"openai",&nbsp;"OpenAI"].</tt></dd></dl>

<hr>
Readonly properties inherited from <a href="langchain_core.load.serializable.html#Serializable">langchain_core.load.serializable.Serializable</a>:<br>
<dl><dt><strong>lc_attributes</strong></dt>
<dd><tt>List&nbsp;of&nbsp;attribute&nbsp;names&nbsp;that&nbsp;should&nbsp;be&nbsp;included&nbsp;in&nbsp;the&nbsp;serialized&nbsp;kwargs.<br>
&nbsp;<br>
These&nbsp;attributes&nbsp;must&nbsp;be&nbsp;accepted&nbsp;by&nbsp;the&nbsp;constructor.<br>
Default&nbsp;is&nbsp;an&nbsp;empty&nbsp;dictionary.</tt></dd>
</dl>
<dl><dt><strong>lc_secrets</strong></dt>
<dd><tt>A&nbsp;map&nbsp;of&nbsp;constructor&nbsp;argument&nbsp;names&nbsp;to&nbsp;secret&nbsp;ids.<br>
&nbsp;<br>
For&nbsp;example,<br>
&nbsp;&nbsp;&nbsp;&nbsp;{"openai_api_key":&nbsp;"OPENAI_API_KEY"}</tt></dd>
</dl>
<hr>
Methods inherited from <a href="pydantic.main.html#BaseModel">pydantic.main.BaseModel</a>:<br>
<dl><dt><a name="ChatVertexAI-__copy__"><strong>__copy__</strong></a>(self) -&gt; 'Self'</dt><dd><tt>Returns&nbsp;a&nbsp;shallow&nbsp;copy&nbsp;of&nbsp;the&nbsp;model.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__deepcopy__"><strong>__deepcopy__</strong></a>(self, memo: 'dict[int, Any] | None' = None) -&gt; 'Self'</dt><dd><tt>Returns&nbsp;a&nbsp;deep&nbsp;copy&nbsp;of&nbsp;the&nbsp;model.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__delattr__"><strong>__delattr__</strong></a>(self, item: 'str') -&gt; 'Any'</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__eq__"><strong>__eq__</strong></a>(self, other: 'Any') -&gt; 'bool'</dt><dd><tt>Return&nbsp;self==value.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__getattr__"><strong>__getattr__</strong></a>(self, item: 'str') -&gt; 'Any'</dt></dl>

<dl><dt><a name="ChatVertexAI-__getstate__"><strong>__getstate__</strong></a>(self) -&gt; 'dict[Any, Any]'</dt></dl>

<dl><dt><a name="ChatVertexAI-__iter__"><strong>__iter__</strong></a>(self) -&gt; 'TupleGenerator'</dt><dd><tt>So&nbsp;`<a href="#ChatVertexAI-dict">dict</a>(model)`&nbsp;works.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__pretty__"><strong>__pretty__</strong></a>(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -&gt; 'typing.Generator[Any, None, None]'</dt><dd><tt>Used&nbsp;by&nbsp;devtools&nbsp;(<a href="https://python-devtools.helpmanual.io/">https://python-devtools.helpmanual.io/</a>)&nbsp;to&nbsp;pretty&nbsp;print&nbsp;objects.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__replace__"><strong>__replace__</strong></a>(self, **changes: 'Any') -&gt; 'Self'</dt><dd><tt>#&nbsp;Because&nbsp;we&nbsp;make&nbsp;use&nbsp;of&nbsp;`@dataclass_transform()`,&nbsp;`__replace__`&nbsp;is&nbsp;already&nbsp;synthesized&nbsp;by<br>
#&nbsp;type&nbsp;checkers,&nbsp;so&nbsp;we&nbsp;define&nbsp;the&nbsp;implementation&nbsp;in&nbsp;this&nbsp;`if&nbsp;not&nbsp;TYPE_CHECKING:`&nbsp;block:</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__repr__"><strong>__repr__</strong></a>(self) -&gt; 'str'</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__repr_name__"><strong>__repr_name__</strong></a>(self) -&gt; 'str'</dt><dd><tt>Name&nbsp;of&nbsp;the&nbsp;instance's&nbsp;class,&nbsp;used&nbsp;in&nbsp;__repr__.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__repr_recursion__"><strong>__repr_recursion__</strong></a>(self, object: 'Any') -&gt; 'str'</dt><dd><tt>Returns&nbsp;the&nbsp;string&nbsp;representation&nbsp;of&nbsp;a&nbsp;recursive&nbsp;object.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__repr_str__"><strong>__repr_str__</strong></a>(self, join_str: 'str') -&gt; 'str'</dt></dl>

<dl><dt><a name="ChatVertexAI-__rich_repr__"><strong>__rich_repr__</strong></a>(self) -&gt; 'RichReprResult'</dt><dd><tt>Used&nbsp;by&nbsp;Rich&nbsp;(<a href="https://rich.readthedocs.io/en/stable/pretty.html">https://rich.readthedocs.io/en/stable/pretty.html</a>)&nbsp;to&nbsp;pretty&nbsp;print&nbsp;objects.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__setattr__"><strong>__setattr__</strong></a>(self, name: 'str', value: 'Any') -&gt; 'None'</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__setstate__"><strong>__setstate__</strong></a>(self, state: 'dict[Any, Any]') -&gt; 'None'</dt></dl>

<dl><dt><a name="ChatVertexAI-__str__"><strong>__str__</strong></a>(self) -&gt; 'str'</dt><dd><tt>Return&nbsp;str(self).</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-copy"><strong>copy</strong></a>(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -&gt; 'Self'</dt><dd><tt>Returns&nbsp;a&nbsp;copy&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
!!!&nbsp;warning&nbsp;"Deprecated"<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;is&nbsp;now&nbsp;deprecated;&nbsp;use&nbsp;`model_copy`&nbsp;instead.<br>
&nbsp;<br>
If&nbsp;you&nbsp;need&nbsp;`include`&nbsp;or&nbsp;`exclude`,&nbsp;use:<br>
&nbsp;<br>
```python&nbsp;{test="skip"&nbsp;lint="skip"}<br>
data&nbsp;=&nbsp;self.<a href="#ChatVertexAI-model_dump">model_dump</a>(include=include,&nbsp;exclude=exclude,&nbsp;round_trip=True)<br>
data&nbsp;=&nbsp;{**data,&nbsp;**(update&nbsp;or&nbsp;{})}<br>
copied&nbsp;=&nbsp;self.<a href="#ChatVertexAI-model_validate">model_validate</a>(data)<br>
```<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;include:&nbsp;Optional&nbsp;set&nbsp;or&nbsp;mapping&nbsp;specifying&nbsp;which&nbsp;fields&nbsp;to&nbsp;include&nbsp;in&nbsp;the&nbsp;copied&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude:&nbsp;Optional&nbsp;set&nbsp;or&nbsp;mapping&nbsp;specifying&nbsp;which&nbsp;fields&nbsp;to&nbsp;exclude&nbsp;in&nbsp;the&nbsp;copied&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;update:&nbsp;Optional&nbsp;dictionary&nbsp;of&nbsp;field-value&nbsp;pairs&nbsp;to&nbsp;override&nbsp;field&nbsp;values&nbsp;in&nbsp;the&nbsp;copied&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;deep:&nbsp;If&nbsp;True,&nbsp;the&nbsp;values&nbsp;of&nbsp;fields&nbsp;that&nbsp;are&nbsp;Pydantic&nbsp;models&nbsp;will&nbsp;be&nbsp;deep-copied.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;copy&nbsp;of&nbsp;the&nbsp;model&nbsp;with&nbsp;included,&nbsp;excluded&nbsp;and&nbsp;updated&nbsp;fields&nbsp;as&nbsp;specified.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-json"><strong>json</strong></a>(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -&gt; 'str'</dt></dl>

<dl><dt><a name="ChatVertexAI-model_copy"><strong>model_copy</strong></a>(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -&gt; 'Self'</dt><dd><tt>Usage&nbsp;docs:&nbsp;<a href="https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy">https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy</a><br>
&nbsp;<br>
Returns&nbsp;a&nbsp;copy&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;update:&nbsp;Values&nbsp;to&nbsp;change/add&nbsp;in&nbsp;the&nbsp;new&nbsp;model.&nbsp;Note:&nbsp;the&nbsp;data&nbsp;is&nbsp;not&nbsp;validated<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;before&nbsp;creating&nbsp;the&nbsp;new&nbsp;model.&nbsp;You&nbsp;should&nbsp;trust&nbsp;this&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;deep:&nbsp;Set&nbsp;to&nbsp;`True`&nbsp;to&nbsp;make&nbsp;a&nbsp;deep&nbsp;copy&nbsp;of&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;New&nbsp;model&nbsp;instance.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-model_dump"><strong>model_dump</strong></a>(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -&gt; 'dict[str, Any]'</dt><dd><tt>Usage&nbsp;docs:&nbsp;<a href="https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump">https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump</a><br>
&nbsp;<br>
Generate&nbsp;a&nbsp;dictionary&nbsp;representation&nbsp;of&nbsp;the&nbsp;model,&nbsp;optionally&nbsp;specifying&nbsp;which&nbsp;fields&nbsp;to&nbsp;include&nbsp;or&nbsp;exclude.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;mode:&nbsp;The&nbsp;mode&nbsp;in&nbsp;which&nbsp;`to_python`&nbsp;should&nbsp;run.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;mode&nbsp;is&nbsp;'json',&nbsp;the&nbsp;output&nbsp;will&nbsp;only&nbsp;contain&nbsp;JSON&nbsp;serializable&nbsp;types.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;mode&nbsp;is&nbsp;'python',&nbsp;the&nbsp;output&nbsp;may&nbsp;contain&nbsp;non-JSON-serializable&nbsp;Python&nbsp;objects.<br>
&nbsp;&nbsp;&nbsp;&nbsp;include:&nbsp;A&nbsp;set&nbsp;of&nbsp;fields&nbsp;to&nbsp;include&nbsp;in&nbsp;the&nbsp;output.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude:&nbsp;A&nbsp;set&nbsp;of&nbsp;fields&nbsp;to&nbsp;exclude&nbsp;from&nbsp;the&nbsp;output.<br>
&nbsp;&nbsp;&nbsp;&nbsp;context:&nbsp;Additional&nbsp;context&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;serializer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;by_alias:&nbsp;Whether&nbsp;to&nbsp;use&nbsp;the&nbsp;field's&nbsp;alias&nbsp;in&nbsp;the&nbsp;dictionary&nbsp;key&nbsp;if&nbsp;defined.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_unset:&nbsp;Whether&nbsp;to&nbsp;exclude&nbsp;fields&nbsp;that&nbsp;have&nbsp;not&nbsp;been&nbsp;explicitly&nbsp;set.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_defaults:&nbsp;Whether&nbsp;to&nbsp;exclude&nbsp;fields&nbsp;that&nbsp;are&nbsp;set&nbsp;to&nbsp;their&nbsp;default&nbsp;value.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_none:&nbsp;Whether&nbsp;to&nbsp;exclude&nbsp;fields&nbsp;that&nbsp;have&nbsp;a&nbsp;value&nbsp;of&nbsp;`None`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;round_trip:&nbsp;If&nbsp;True,&nbsp;dumped&nbsp;values&nbsp;should&nbsp;be&nbsp;valid&nbsp;as&nbsp;input&nbsp;for&nbsp;non-idempotent&nbsp;types&nbsp;such&nbsp;as&nbsp;Json[T].<br>
&nbsp;&nbsp;&nbsp;&nbsp;warnings:&nbsp;How&nbsp;to&nbsp;handle&nbsp;serialization&nbsp;errors.&nbsp;False/"none"&nbsp;ignores&nbsp;them,&nbsp;True/"warn"&nbsp;logs&nbsp;errors,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"error"&nbsp;raises&nbsp;a&nbsp;[`PydanticSerializationError`][pydantic_core.PydanticSerializationError].<br>
&nbsp;&nbsp;&nbsp;&nbsp;serialize_as_any:&nbsp;Whether&nbsp;to&nbsp;serialize&nbsp;fields&nbsp;with&nbsp;duck-typing&nbsp;serialization&nbsp;behavior.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;representation&nbsp;of&nbsp;the&nbsp;model.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-model_dump_json"><strong>model_dump_json</strong></a>(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -&gt; 'str'</dt><dd><tt>Usage&nbsp;docs:&nbsp;<a href="https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json">https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json</a><br>
&nbsp;<br>
Generates&nbsp;a&nbsp;JSON&nbsp;representation&nbsp;of&nbsp;the&nbsp;model&nbsp;using&nbsp;Pydantic's&nbsp;`to_json`&nbsp;method.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;indent:&nbsp;Indentation&nbsp;to&nbsp;use&nbsp;in&nbsp;the&nbsp;JSON&nbsp;output.&nbsp;If&nbsp;None&nbsp;is&nbsp;passed,&nbsp;the&nbsp;output&nbsp;will&nbsp;be&nbsp;compact.<br>
&nbsp;&nbsp;&nbsp;&nbsp;include:&nbsp;Field(s)&nbsp;to&nbsp;include&nbsp;in&nbsp;the&nbsp;JSON&nbsp;output.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude:&nbsp;Field(s)&nbsp;to&nbsp;exclude&nbsp;from&nbsp;the&nbsp;JSON&nbsp;output.<br>
&nbsp;&nbsp;&nbsp;&nbsp;context:&nbsp;Additional&nbsp;context&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;serializer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;by_alias:&nbsp;Whether&nbsp;to&nbsp;serialize&nbsp;using&nbsp;field&nbsp;aliases.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_unset:&nbsp;Whether&nbsp;to&nbsp;exclude&nbsp;fields&nbsp;that&nbsp;have&nbsp;not&nbsp;been&nbsp;explicitly&nbsp;set.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_defaults:&nbsp;Whether&nbsp;to&nbsp;exclude&nbsp;fields&nbsp;that&nbsp;are&nbsp;set&nbsp;to&nbsp;their&nbsp;default&nbsp;value.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_none:&nbsp;Whether&nbsp;to&nbsp;exclude&nbsp;fields&nbsp;that&nbsp;have&nbsp;a&nbsp;value&nbsp;of&nbsp;`None`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;round_trip:&nbsp;If&nbsp;True,&nbsp;dumped&nbsp;values&nbsp;should&nbsp;be&nbsp;valid&nbsp;as&nbsp;input&nbsp;for&nbsp;non-idempotent&nbsp;types&nbsp;such&nbsp;as&nbsp;Json[T].<br>
&nbsp;&nbsp;&nbsp;&nbsp;warnings:&nbsp;How&nbsp;to&nbsp;handle&nbsp;serialization&nbsp;errors.&nbsp;False/"none"&nbsp;ignores&nbsp;them,&nbsp;True/"warn"&nbsp;logs&nbsp;errors,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"error"&nbsp;raises&nbsp;a&nbsp;[`PydanticSerializationError`][pydantic_core.PydanticSerializationError].<br>
&nbsp;&nbsp;&nbsp;&nbsp;serialize_as_any:&nbsp;Whether&nbsp;to&nbsp;serialize&nbsp;fields&nbsp;with&nbsp;duck-typing&nbsp;serialization&nbsp;behavior.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;JSON&nbsp;string&nbsp;representation&nbsp;of&nbsp;the&nbsp;model.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-model_post_init"><strong>model_post_init</strong></a>(self, _BaseModel__context: 'Any') -&gt; 'None'</dt><dd><tt>Override&nbsp;this&nbsp;method&nbsp;to&nbsp;perform&nbsp;additional&nbsp;initialization&nbsp;after&nbsp;`__init__`&nbsp;and&nbsp;`model_construct`.<br>
This&nbsp;is&nbsp;useful&nbsp;if&nbsp;you&nbsp;want&nbsp;to&nbsp;do&nbsp;some&nbsp;validation&nbsp;that&nbsp;requires&nbsp;the&nbsp;entire&nbsp;model&nbsp;to&nbsp;be&nbsp;initialized.</tt></dd></dl>

<hr>
Class methods inherited from <a href="pydantic.main.html#BaseModel">pydantic.main.BaseModel</a>:<br>
<dl><dt><a name="ChatVertexAI-__class_getitem__"><strong>__class_getitem__</strong></a>(typevar_values: 'type[Any] | tuple[type[Any], ...]') -&gt; 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt></dl>

<dl><dt><a name="ChatVertexAI-__get_pydantic_core_schema__"><strong>__get_pydantic_core_schema__</strong></a>(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -&gt; 'CoreSchema'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Hook&nbsp;into&nbsp;generating&nbsp;the&nbsp;model's&nbsp;CoreSchema.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;source:&nbsp;The&nbsp;class&nbsp;we&nbsp;are&nbsp;generating&nbsp;a&nbsp;schema&nbsp;for.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;will&nbsp;generally&nbsp;be&nbsp;the&nbsp;same&nbsp;as&nbsp;the&nbsp;`cls`&nbsp;argument&nbsp;if&nbsp;this&nbsp;is&nbsp;a&nbsp;classmethod.<br>
&nbsp;&nbsp;&nbsp;&nbsp;handler:&nbsp;A&nbsp;callable&nbsp;that&nbsp;calls&nbsp;into&nbsp;Pydantic's&nbsp;internal&nbsp;CoreSchema&nbsp;generation&nbsp;logic.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;`pydantic-core`&nbsp;`CoreSchema`.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__get_pydantic_json_schema__"><strong>__get_pydantic_json_schema__</strong></a>(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -&gt; 'JsonSchemaValue'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Hook&nbsp;into&nbsp;generating&nbsp;the&nbsp;model's&nbsp;JSON&nbsp;schema.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;core_schema:&nbsp;A&nbsp;`pydantic-core`&nbsp;CoreSchema.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You&nbsp;can&nbsp;ignore&nbsp;this&nbsp;argument&nbsp;and&nbsp;call&nbsp;the&nbsp;handler&nbsp;with&nbsp;a&nbsp;new&nbsp;CoreSchema,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wrap&nbsp;this&nbsp;CoreSchema&nbsp;(`{'type':&nbsp;'nullable',&nbsp;'schema':&nbsp;current_schema}`),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or&nbsp;just&nbsp;call&nbsp;the&nbsp;handler&nbsp;with&nbsp;the&nbsp;original&nbsp;schema.<br>
&nbsp;&nbsp;&nbsp;&nbsp;handler:&nbsp;Call&nbsp;into&nbsp;Pydantic's&nbsp;internal&nbsp;JSON&nbsp;schema&nbsp;generation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;will&nbsp;raise&nbsp;a&nbsp;`pydantic.errors.PydanticInvalidForJsonSchema`&nbsp;if&nbsp;JSON&nbsp;schema<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;generation&nbsp;fails.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Since&nbsp;this&nbsp;gets&nbsp;called&nbsp;by&nbsp;`BaseModel.model_json_schema`&nbsp;you&nbsp;can&nbsp;override&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`schema_generator`&nbsp;argument&nbsp;to&nbsp;that&nbsp;function&nbsp;to&nbsp;change&nbsp;JSON&nbsp;schema&nbsp;generation&nbsp;globally<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;a&nbsp;type.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;JSON&nbsp;schema,&nbsp;as&nbsp;a&nbsp;Python&nbsp;object.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__pydantic_init_subclass__"><strong>__pydantic_init_subclass__</strong></a>(**kwargs: 'Any') -&gt; 'None'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>This&nbsp;is&nbsp;intended&nbsp;to&nbsp;behave&nbsp;just&nbsp;like&nbsp;`__init_subclass__`,&nbsp;but&nbsp;is&nbsp;called&nbsp;by&nbsp;`ModelMetaclass`<br>
only&nbsp;after&nbsp;the&nbsp;class&nbsp;is&nbsp;actually&nbsp;fully&nbsp;initialized.&nbsp;In&nbsp;particular,&nbsp;attributes&nbsp;like&nbsp;`model_fields`&nbsp;will<br>
be&nbsp;present&nbsp;when&nbsp;this&nbsp;is&nbsp;called.<br>
&nbsp;<br>
This&nbsp;is&nbsp;necessary&nbsp;because&nbsp;`__init_subclass__`&nbsp;will&nbsp;always&nbsp;be&nbsp;called&nbsp;by&nbsp;`type.__new__`,<br>
and&nbsp;it&nbsp;would&nbsp;require&nbsp;a&nbsp;prohibitively&nbsp;large&nbsp;refactor&nbsp;to&nbsp;the&nbsp;`ModelMetaclass`&nbsp;to&nbsp;ensure&nbsp;that<br>
`type.__new__`&nbsp;was&nbsp;called&nbsp;in&nbsp;such&nbsp;a&nbsp;manner&nbsp;that&nbsp;the&nbsp;class&nbsp;would&nbsp;already&nbsp;be&nbsp;sufficiently&nbsp;initialized.<br>
&nbsp;<br>
This&nbsp;will&nbsp;receive&nbsp;the&nbsp;same&nbsp;`kwargs`&nbsp;that&nbsp;would&nbsp;be&nbsp;passed&nbsp;to&nbsp;the&nbsp;standard&nbsp;`__init_subclass__`,&nbsp;namely,<br>
any&nbsp;kwargs&nbsp;passed&nbsp;to&nbsp;the&nbsp;class&nbsp;definition&nbsp;that&nbsp;aren't&nbsp;used&nbsp;internally&nbsp;by&nbsp;pydantic.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;**kwargs:&nbsp;Any&nbsp;keyword&nbsp;arguments&nbsp;passed&nbsp;to&nbsp;the&nbsp;class&nbsp;definition&nbsp;that&nbsp;aren't&nbsp;used&nbsp;internally<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;by&nbsp;pydantic.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-construct"><strong>construct</strong></a>(_fields_set: 'set[str] | None' = None, **values: 'Any') -&gt; 'Self'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt></dl>

<dl><dt><a name="ChatVertexAI-from_orm"><strong>from_orm</strong></a>(obj: 'Any') -&gt; 'Self'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt></dl>

<dl><dt><a name="ChatVertexAI-model_construct"><strong>model_construct</strong></a>(_fields_set: 'set[str] | None' = None, **values: 'Any') -&gt; 'Self'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Creates&nbsp;a&nbsp;new&nbsp;instance&nbsp;of&nbsp;the&nbsp;`Model`&nbsp;class&nbsp;with&nbsp;validated&nbsp;data.<br>
&nbsp;<br>
Creates&nbsp;a&nbsp;new&nbsp;model&nbsp;setting&nbsp;`__dict__`&nbsp;and&nbsp;`__pydantic_fields_set__`&nbsp;from&nbsp;trusted&nbsp;or&nbsp;pre-validated&nbsp;data.<br>
Default&nbsp;values&nbsp;are&nbsp;respected,&nbsp;but&nbsp;no&nbsp;other&nbsp;validation&nbsp;is&nbsp;performed.<br>
&nbsp;<br>
!!!&nbsp;note<br>
&nbsp;&nbsp;&nbsp;&nbsp;`<a href="#ChatVertexAI-model_construct">model_construct</a>()`&nbsp;generally&nbsp;respects&nbsp;the&nbsp;`model_config.extra`&nbsp;setting&nbsp;on&nbsp;the&nbsp;provided&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;That&nbsp;is,&nbsp;if&nbsp;`model_config.extra&nbsp;==&nbsp;'allow'`,&nbsp;then&nbsp;all&nbsp;extra&nbsp;passed&nbsp;values&nbsp;are&nbsp;added&nbsp;to&nbsp;the&nbsp;model&nbsp;instance's&nbsp;`__dict__`<br>
&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;`__pydantic_extra__`&nbsp;fields.&nbsp;If&nbsp;`model_config.extra&nbsp;==&nbsp;'ignore'`&nbsp;(the&nbsp;default),&nbsp;then&nbsp;all&nbsp;extra&nbsp;passed&nbsp;values&nbsp;are&nbsp;ignored.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Because&nbsp;no&nbsp;validation&nbsp;is&nbsp;performed&nbsp;with&nbsp;a&nbsp;call&nbsp;to&nbsp;`<a href="#ChatVertexAI-model_construct">model_construct</a>()`,&nbsp;having&nbsp;`model_config.extra&nbsp;==&nbsp;'forbid'`&nbsp;does&nbsp;not&nbsp;result&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;an&nbsp;error&nbsp;if&nbsp;extra&nbsp;values&nbsp;are&nbsp;passed,&nbsp;but&nbsp;they&nbsp;will&nbsp;be&nbsp;ignored.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;_fields_set:&nbsp;A&nbsp;set&nbsp;of&nbsp;field&nbsp;names&nbsp;that&nbsp;were&nbsp;originally&nbsp;explicitly&nbsp;set&nbsp;during&nbsp;instantiation.&nbsp;If&nbsp;provided,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;is&nbsp;directly&nbsp;used&nbsp;for&nbsp;the&nbsp;[`model_fields_set`][pydantic.BaseModel.model_fields_set]&nbsp;attribute.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Otherwise,&nbsp;the&nbsp;field&nbsp;names&nbsp;from&nbsp;the&nbsp;`values`&nbsp;argument&nbsp;will&nbsp;be&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;values:&nbsp;Trusted&nbsp;or&nbsp;pre-validated&nbsp;data&nbsp;dictionary.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;instance&nbsp;of&nbsp;the&nbsp;`Model`&nbsp;class&nbsp;with&nbsp;validated&nbsp;data.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-model_json_schema"><strong>model_json_schema</strong></a>(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = &lt;class 'pydantic.json_schema.GenerateJsonSchema'&gt;, mode: 'JsonSchemaMode' = 'validation') -&gt; 'dict[str, Any]'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Generates&nbsp;a&nbsp;JSON&nbsp;schema&nbsp;for&nbsp;a&nbsp;model&nbsp;class.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;by_alias:&nbsp;Whether&nbsp;to&nbsp;use&nbsp;attribute&nbsp;aliases&nbsp;or&nbsp;not.<br>
&nbsp;&nbsp;&nbsp;&nbsp;ref_template:&nbsp;The&nbsp;reference&nbsp;template.<br>
&nbsp;&nbsp;&nbsp;&nbsp;schema_generator:&nbsp;To&nbsp;override&nbsp;the&nbsp;logic&nbsp;used&nbsp;to&nbsp;generate&nbsp;the&nbsp;JSON&nbsp;schema,&nbsp;as&nbsp;a&nbsp;subclass&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`GenerateJsonSchema`&nbsp;with&nbsp;your&nbsp;desired&nbsp;modifications<br>
&nbsp;&nbsp;&nbsp;&nbsp;mode:&nbsp;The&nbsp;mode&nbsp;in&nbsp;which&nbsp;to&nbsp;generate&nbsp;the&nbsp;schema.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;JSON&nbsp;schema&nbsp;for&nbsp;the&nbsp;given&nbsp;model&nbsp;class.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-model_parametrized_name"><strong>model_parametrized_name</strong></a>(params: 'tuple[type[Any], ...]') -&gt; 'str'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Compute&nbsp;the&nbsp;class&nbsp;name&nbsp;for&nbsp;parametrizations&nbsp;of&nbsp;generic&nbsp;classes.<br>
&nbsp;<br>
This&nbsp;method&nbsp;can&nbsp;be&nbsp;overridden&nbsp;to&nbsp;achieve&nbsp;a&nbsp;custom&nbsp;naming&nbsp;scheme&nbsp;for&nbsp;generic&nbsp;BaseModels.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;params:&nbsp;Tuple&nbsp;of&nbsp;types&nbsp;of&nbsp;the&nbsp;class.&nbsp;Given&nbsp;a&nbsp;generic&nbsp;class<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`Model`&nbsp;with&nbsp;2&nbsp;type&nbsp;variables&nbsp;and&nbsp;a&nbsp;concrete&nbsp;model&nbsp;`Model[str,&nbsp;int]`,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;value&nbsp;`(str,&nbsp;int)`&nbsp;would&nbsp;be&nbsp;passed&nbsp;to&nbsp;`params`.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;String&nbsp;representing&nbsp;the&nbsp;new&nbsp;class&nbsp;where&nbsp;`params`&nbsp;are&nbsp;passed&nbsp;to&nbsp;`cls`&nbsp;as&nbsp;type&nbsp;variables.<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;TypeError:&nbsp;Raised&nbsp;when&nbsp;trying&nbsp;to&nbsp;generate&nbsp;concrete&nbsp;names&nbsp;for&nbsp;non-generic&nbsp;models.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-model_rebuild"><strong>model_rebuild</strong></a>(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -&gt; 'bool | None'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Try&nbsp;to&nbsp;rebuild&nbsp;the&nbsp;pydantic-core&nbsp;schema&nbsp;for&nbsp;the&nbsp;model.<br>
&nbsp;<br>
This&nbsp;may&nbsp;be&nbsp;necessary&nbsp;when&nbsp;one&nbsp;of&nbsp;the&nbsp;annotations&nbsp;is&nbsp;a&nbsp;ForwardRef&nbsp;which&nbsp;could&nbsp;not&nbsp;be&nbsp;resolved&nbsp;during<br>
the&nbsp;initial&nbsp;attempt&nbsp;to&nbsp;build&nbsp;the&nbsp;schema,&nbsp;and&nbsp;automatic&nbsp;rebuilding&nbsp;fails.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;force:&nbsp;Whether&nbsp;to&nbsp;force&nbsp;the&nbsp;rebuilding&nbsp;of&nbsp;the&nbsp;model&nbsp;schema,&nbsp;defaults&nbsp;to&nbsp;`False`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;raise_errors:&nbsp;Whether&nbsp;to&nbsp;raise&nbsp;errors,&nbsp;defaults&nbsp;to&nbsp;`True`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_parent_namespace_depth:&nbsp;The&nbsp;depth&nbsp;level&nbsp;of&nbsp;the&nbsp;parent&nbsp;namespace,&nbsp;defaults&nbsp;to&nbsp;2.<br>
&nbsp;&nbsp;&nbsp;&nbsp;_types_namespace:&nbsp;The&nbsp;types&nbsp;namespace,&nbsp;defaults&nbsp;to&nbsp;`None`.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Returns&nbsp;`None`&nbsp;if&nbsp;the&nbsp;schema&nbsp;is&nbsp;already&nbsp;"complete"&nbsp;and&nbsp;rebuilding&nbsp;was&nbsp;not&nbsp;required.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;rebuilding&nbsp;_was_&nbsp;required,&nbsp;returns&nbsp;`True`&nbsp;if&nbsp;rebuilding&nbsp;was&nbsp;successful,&nbsp;otherwise&nbsp;`False`.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-model_validate"><strong>model_validate</strong></a>(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -&gt; 'Self'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Validate&nbsp;a&nbsp;pydantic&nbsp;model&nbsp;instance.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;obj:&nbsp;The&nbsp;object&nbsp;to&nbsp;validate.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict:&nbsp;Whether&nbsp;to&nbsp;enforce&nbsp;types&nbsp;strictly.<br>
&nbsp;&nbsp;&nbsp;&nbsp;from_attributes:&nbsp;Whether&nbsp;to&nbsp;extract&nbsp;data&nbsp;from&nbsp;object&nbsp;attributes.<br>
&nbsp;&nbsp;&nbsp;&nbsp;context:&nbsp;Additional&nbsp;context&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;validator.<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValidationError:&nbsp;If&nbsp;the&nbsp;object&nbsp;could&nbsp;not&nbsp;be&nbsp;validated.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;validated&nbsp;model&nbsp;instance.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-model_validate_json"><strong>model_validate_json</strong></a>(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -&gt; 'Self'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Usage&nbsp;docs:&nbsp;<a href="https://docs.pydantic.dev/2.10/concepts/json/#json-parsing">https://docs.pydantic.dev/2.10/concepts/json/#json-parsing</a><br>
&nbsp;<br>
Validate&nbsp;the&nbsp;given&nbsp;JSON&nbsp;data&nbsp;against&nbsp;the&nbsp;Pydantic&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;json_data:&nbsp;The&nbsp;JSON&nbsp;data&nbsp;to&nbsp;validate.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict:&nbsp;Whether&nbsp;to&nbsp;enforce&nbsp;types&nbsp;strictly.<br>
&nbsp;&nbsp;&nbsp;&nbsp;context:&nbsp;Extra&nbsp;variables&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;validator.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;validated&nbsp;Pydantic&nbsp;model.<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;ValidationError:&nbsp;If&nbsp;`json_data`&nbsp;is&nbsp;not&nbsp;a&nbsp;JSON&nbsp;string&nbsp;or&nbsp;the&nbsp;object&nbsp;could&nbsp;not&nbsp;be&nbsp;validated.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-model_validate_strings"><strong>model_validate_strings</strong></a>(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -&gt; 'Self'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>Validate&nbsp;the&nbsp;given&nbsp;object&nbsp;with&nbsp;string&nbsp;data&nbsp;against&nbsp;the&nbsp;Pydantic&nbsp;model.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;obj:&nbsp;The&nbsp;object&nbsp;containing&nbsp;string&nbsp;data&nbsp;to&nbsp;validate.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict:&nbsp;Whether&nbsp;to&nbsp;enforce&nbsp;types&nbsp;strictly.<br>
&nbsp;&nbsp;&nbsp;&nbsp;context:&nbsp;Extra&nbsp;variables&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;validator.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;validated&nbsp;Pydantic&nbsp;model.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-parse_file"><strong>parse_file</strong></a>(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -&gt; 'Self'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt></dl>

<dl><dt><a name="ChatVertexAI-parse_obj"><strong>parse_obj</strong></a>(obj: 'Any') -&gt; 'Self'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt></dl>

<dl><dt><a name="ChatVertexAI-parse_raw"><strong>parse_raw</strong></a>(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -&gt; 'Self'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt></dl>

<dl><dt><a name="ChatVertexAI-schema"><strong>schema</strong></a>(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -&gt; 'Dict[str, Any]'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt></dl>

<dl><dt><a name="ChatVertexAI-schema_json"><strong>schema_json</strong></a>(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -&gt; 'str'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt></dl>

<dl><dt><a name="ChatVertexAI-update_forward_refs"><strong>update_forward_refs</strong></a>(**localns: 'Any') -&gt; 'None'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt></dl>

<dl><dt><a name="ChatVertexAI-validate"><strong>validate</strong></a>(value: 'Any') -&gt; 'Self'<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt></dl>

<hr>
Readonly properties inherited from <a href="pydantic.main.html#BaseModel">pydantic.main.BaseModel</a>:<br>
<dl><dt><strong>__fields_set__</strong></dt>
</dl>
<dl><dt><strong>model_computed_fields</strong></dt>
<dd><tt>Get&nbsp;metadata&nbsp;about&nbsp;the&nbsp;computed&nbsp;fields&nbsp;defined&nbsp;on&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Deprecation&nbsp;warning:&nbsp;you&nbsp;should&nbsp;be&nbsp;getting&nbsp;this&nbsp;information&nbsp;from&nbsp;the&nbsp;model&nbsp;class,&nbsp;not&nbsp;from&nbsp;an&nbsp;instance.<br>
In&nbsp;V3,&nbsp;this&nbsp;property&nbsp;will&nbsp;be&nbsp;removed&nbsp;from&nbsp;the&nbsp;`BaseModel`&nbsp;class.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;mapping&nbsp;of&nbsp;computed&nbsp;field&nbsp;names&nbsp;to&nbsp;[`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo]&nbsp;objects.</tt></dd>
</dl>
<dl><dt><strong>model_extra</strong></dt>
<dd><tt>Get&nbsp;extra&nbsp;fields&nbsp;set&nbsp;during&nbsp;validation.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;extra&nbsp;fields,&nbsp;or&nbsp;`None`&nbsp;if&nbsp;`config.extra`&nbsp;is&nbsp;not&nbsp;set&nbsp;to&nbsp;`"allow"`.</tt></dd>
</dl>
<dl><dt><strong>model_fields</strong></dt>
<dd><tt>Get&nbsp;metadata&nbsp;about&nbsp;the&nbsp;fields&nbsp;defined&nbsp;on&nbsp;the&nbsp;model.<br>
&nbsp;<br>
Deprecation&nbsp;warning:&nbsp;you&nbsp;should&nbsp;be&nbsp;getting&nbsp;this&nbsp;information&nbsp;from&nbsp;the&nbsp;model&nbsp;class,&nbsp;not&nbsp;from&nbsp;an&nbsp;instance.<br>
In&nbsp;V3,&nbsp;this&nbsp;property&nbsp;will&nbsp;be&nbsp;removed&nbsp;from&nbsp;the&nbsp;`BaseModel`&nbsp;class.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;mapping&nbsp;of&nbsp;field&nbsp;names&nbsp;to&nbsp;[`FieldInfo`][pydantic.fields.FieldInfo]&nbsp;objects.</tt></dd>
</dl>
<dl><dt><strong>model_fields_set</strong></dt>
<dd><tt>Returns&nbsp;the&nbsp;set&nbsp;of&nbsp;fields&nbsp;that&nbsp;have&nbsp;been&nbsp;explicitly&nbsp;set&nbsp;on&nbsp;this&nbsp;model&nbsp;instance.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;set&nbsp;of&nbsp;strings&nbsp;representing&nbsp;the&nbsp;fields&nbsp;that&nbsp;have&nbsp;been&nbsp;set,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i.e.&nbsp;that&nbsp;were&nbsp;not&nbsp;filled&nbsp;from&nbsp;defaults.</tt></dd>
</dl>
<hr>
Data descriptors inherited from <a href="pydantic.main.html#BaseModel">pydantic.main.BaseModel</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__pydantic_extra__</strong></dt>
</dl>
<dl><dt><strong>__pydantic_fields_set__</strong></dt>
</dl>
<dl><dt><strong>__pydantic_private__</strong></dt>
</dl>
<hr>
Data and other attributes inherited from <a href="pydantic.main.html#BaseModel">pydantic.main.BaseModel</a>:<br>
<dl><dt><strong>__hash__</strong> = None</dl>

<dl><dt><strong>__pydantic_root_model__</strong> = False</dl>

<hr>
Methods inherited from <a href="langchain_core.runnables.base.html#Runnable">langchain_core.runnables.base.Runnable</a>:<br>
<dl><dt><a name="ChatVertexAI-__or__"><strong>__or__</strong></a>(self, other: 'Union[Runnable[Any, Other], Callable[[Any], Other], Callable[[Iterator[Any]], Iterator[Other]], Mapping[str, Union[Runnable[Any, Other], Callable[[Any], Other], Any]]]') -&gt; 'RunnableSerializable[Input, Other]'</dt><dd><tt>Compose&nbsp;this&nbsp;Runnable&nbsp;with&nbsp;another&nbsp;object&nbsp;to&nbsp;create&nbsp;a&nbsp;RunnableSequence.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-__ror__"><strong>__ror__</strong></a>(self, other: 'Union[Runnable[Other, Any], Callable[[Other], Any], Callable[[Iterator[Other]], Iterator[Any]], Mapping[str, Union[Runnable[Other, Any], Callable[[Other], Any], Any]]]') -&gt; 'RunnableSerializable[Other, Output]'</dt><dd><tt>Compose&nbsp;this&nbsp;Runnable&nbsp;with&nbsp;another&nbsp;object&nbsp;to&nbsp;create&nbsp;a&nbsp;RunnableSequence.</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-abatch"><strong>abatch</strong></a>(self, inputs: 'list[Input]', config: 'Optional[Union[RunnableConfig, list[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -&gt; 'list[Output]'</dt><dd><tt>Default&nbsp;implementation&nbsp;runs&nbsp;ainvoke&nbsp;in&nbsp;parallel&nbsp;using&nbsp;asyncio.gather.<br>
&nbsp;<br>
The&nbsp;default&nbsp;implementation&nbsp;of&nbsp;batch&nbsp;works&nbsp;well&nbsp;for&nbsp;IO&nbsp;bound&nbsp;runnables.<br>
&nbsp;<br>
Subclasses&nbsp;should&nbsp;override&nbsp;this&nbsp;method&nbsp;if&nbsp;they&nbsp;can&nbsp;batch&nbsp;more&nbsp;efficiently;<br>
e.g.,&nbsp;if&nbsp;the&nbsp;underlying&nbsp;Runnable&nbsp;uses&nbsp;an&nbsp;API&nbsp;which&nbsp;supports&nbsp;a&nbsp;batch&nbsp;mode.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;inputs:&nbsp;A&nbsp;list&nbsp;of&nbsp;inputs&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;A&nbsp;config&nbsp;to&nbsp;use&nbsp;when&nbsp;invoking&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;config&nbsp;supports&nbsp;standard&nbsp;keys&nbsp;like&nbsp;'tags',&nbsp;'metadata'&nbsp;for&nbsp;tracing<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;purposes,&nbsp;'max_concurrency'&nbsp;for&nbsp;controlling&nbsp;how&nbsp;much&nbsp;work&nbsp;to&nbsp;do<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;parallel,&nbsp;and&nbsp;other&nbsp;keys.&nbsp;Please&nbsp;refer&nbsp;to&nbsp;the&nbsp;RunnableConfig<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;more&nbsp;details.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;return_exceptions:&nbsp;Whether&nbsp;to&nbsp;return&nbsp;exceptions&nbsp;instead&nbsp;of&nbsp;raising&nbsp;them.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs:&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;list&nbsp;of&nbsp;outputs&nbsp;from&nbsp;the&nbsp;Runnable.</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-abatch_as_completed"><strong>abatch_as_completed</strong></a>(self, inputs: 'Sequence[Input]', config: 'Optional[Union[RunnableConfig, Sequence[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -&gt; 'AsyncIterator[tuple[int, Union[Output, Exception]]]'</dt><dd><tt>Run&nbsp;ainvoke&nbsp;in&nbsp;parallel&nbsp;on&nbsp;a&nbsp;list&nbsp;of&nbsp;inputs,<br>
yielding&nbsp;results&nbsp;as&nbsp;they&nbsp;complete.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;inputs:&nbsp;A&nbsp;list&nbsp;of&nbsp;inputs&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;A&nbsp;config&nbsp;to&nbsp;use&nbsp;when&nbsp;invoking&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;config&nbsp;supports&nbsp;standard&nbsp;keys&nbsp;like&nbsp;'tags',&nbsp;'metadata'&nbsp;for&nbsp;tracing<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;purposes,&nbsp;'max_concurrency'&nbsp;for&nbsp;controlling&nbsp;how&nbsp;much&nbsp;work&nbsp;to&nbsp;do<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;parallel,&nbsp;and&nbsp;other&nbsp;keys.&nbsp;Please&nbsp;refer&nbsp;to&nbsp;the&nbsp;RunnableConfig<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;more&nbsp;details.&nbsp;Defaults&nbsp;to&nbsp;None.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;return_exceptions:&nbsp;Whether&nbsp;to&nbsp;return&nbsp;exceptions&nbsp;instead&nbsp;of&nbsp;raising&nbsp;them.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;False.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs:&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;tuple&nbsp;of&nbsp;the&nbsp;index&nbsp;of&nbsp;the&nbsp;input&nbsp;and&nbsp;the&nbsp;output&nbsp;from&nbsp;the&nbsp;Runnable.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-as_tool"><strong>as_tool</strong></a>(self, args_schema: 'Optional[type[BaseModel]]' = None, *, name: 'Optional[str]' = None, description: 'Optional[str]' = None, arg_types: 'Optional[dict[str, type]]' = None) -&gt; 'BaseTool'</dt><dd><tt>..&nbsp;beta::<br>
&nbsp;&nbsp;&nbsp;This&nbsp;API&nbsp;is&nbsp;in&nbsp;beta&nbsp;and&nbsp;may&nbsp;change&nbsp;in&nbsp;the&nbsp;future.<br>
&nbsp;<br>
Create&nbsp;a&nbsp;BaseTool&nbsp;from&nbsp;a&nbsp;Runnable.<br>
&nbsp;<br>
``as_tool``&nbsp;will&nbsp;instantiate&nbsp;a&nbsp;BaseTool&nbsp;with&nbsp;a&nbsp;name,&nbsp;description,&nbsp;and<br>
``args_schema``&nbsp;from&nbsp;a&nbsp;Runnable.&nbsp;Where&nbsp;possible,&nbsp;schemas&nbsp;are&nbsp;inferred<br>
from&nbsp;``runnable.get_input_schema``.&nbsp;Alternatively&nbsp;(e.g.,&nbsp;if&nbsp;the<br>
Runnable&nbsp;takes&nbsp;a&nbsp;dict&nbsp;as&nbsp;input&nbsp;and&nbsp;the&nbsp;specific&nbsp;dict&nbsp;keys&nbsp;are&nbsp;not&nbsp;typed),<br>
the&nbsp;schema&nbsp;can&nbsp;be&nbsp;specified&nbsp;directly&nbsp;with&nbsp;``args_schema``.&nbsp;You&nbsp;can&nbsp;also<br>
pass&nbsp;``arg_types``&nbsp;to&nbsp;just&nbsp;specify&nbsp;the&nbsp;required&nbsp;arguments&nbsp;and&nbsp;their&nbsp;types.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;args_schema:&nbsp;The&nbsp;schema&nbsp;for&nbsp;the&nbsp;tool.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;The&nbsp;name&nbsp;of&nbsp;the&nbsp;tool.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;description:&nbsp;The&nbsp;description&nbsp;of&nbsp;the&nbsp;tool.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;arg_types:&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;argument&nbsp;names&nbsp;to&nbsp;types.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;BaseTool&nbsp;instance.<br>
&nbsp;<br>
Typed&nbsp;dict&nbsp;input:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;typing&nbsp;import&nbsp;List<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;typing_extensions&nbsp;import&nbsp;TypedDict<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Args(TypedDict):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b:&nbsp;List[int]<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;f(x:&nbsp;Args)&nbsp;-&gt;&nbsp;str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;str(x["a"]&nbsp;*&nbsp;max(x["b"]))<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;runnable&nbsp;=&nbsp;RunnableLambda(f)<br>
&nbsp;&nbsp;&nbsp;&nbsp;as_tool&nbsp;=&nbsp;runnable.<a href="#ChatVertexAI-as_tool">as_tool</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;as_tool.<a href="#ChatVertexAI-invoke">invoke</a>({"a":&nbsp;3,&nbsp;"b":&nbsp;[1,&nbsp;2]})<br>
&nbsp;<br>
``dict``&nbsp;input,&nbsp;specifying&nbsp;schema&nbsp;via&nbsp;``args_schema``:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;typing&nbsp;import&nbsp;Any,&nbsp;Dict,&nbsp;List<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;pydantic&nbsp;import&nbsp;BaseModel,&nbsp;Field<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;f(x:&nbsp;Dict[str,&nbsp;Any])&nbsp;-&gt;&nbsp;str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;str(x["a"]&nbsp;*&nbsp;max(x["b"]))<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;FSchema(BaseModel):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Apply&nbsp;a&nbsp;function&nbsp;to&nbsp;an&nbsp;integer&nbsp;and&nbsp;list&nbsp;of&nbsp;integers."""<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a:&nbsp;int&nbsp;=&nbsp;Field(...,&nbsp;description="Integer")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b:&nbsp;List[int]&nbsp;=&nbsp;Field(...,&nbsp;description="List&nbsp;of&nbsp;ints")<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;runnable&nbsp;=&nbsp;RunnableLambda(f)<br>
&nbsp;&nbsp;&nbsp;&nbsp;as_tool&nbsp;=&nbsp;runnable.<a href="#ChatVertexAI-as_tool">as_tool</a>(FSchema)<br>
&nbsp;&nbsp;&nbsp;&nbsp;as_tool.<a href="#ChatVertexAI-invoke">invoke</a>({"a":&nbsp;3,&nbsp;"b":&nbsp;[1,&nbsp;2]})<br>
&nbsp;<br>
``dict``&nbsp;input,&nbsp;specifying&nbsp;schema&nbsp;via&nbsp;``arg_types``:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;typing&nbsp;import&nbsp;Any,&nbsp;Dict,&nbsp;List<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;f(x:&nbsp;Dict[str,&nbsp;Any])&nbsp;-&gt;&nbsp;str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;str(x["a"]&nbsp;*&nbsp;max(x["b"]))<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;runnable&nbsp;=&nbsp;RunnableLambda(f)<br>
&nbsp;&nbsp;&nbsp;&nbsp;as_tool&nbsp;=&nbsp;runnable.<a href="#ChatVertexAI-as_tool">as_tool</a>(arg_types={"a":&nbsp;int,&nbsp;"b":&nbsp;List[int]})<br>
&nbsp;&nbsp;&nbsp;&nbsp;as_tool.<a href="#ChatVertexAI-invoke">invoke</a>({"a":&nbsp;3,&nbsp;"b":&nbsp;[1,&nbsp;2]})<br>
&nbsp;<br>
String&nbsp;input:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;f(x:&nbsp;str)&nbsp;-&gt;&nbsp;str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;x&nbsp;+&nbsp;"a"<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;g(x:&nbsp;str)&nbsp;-&gt;&nbsp;str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;x&nbsp;+&nbsp;"z"<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;runnable&nbsp;=&nbsp;RunnableLambda(f)&nbsp;|&nbsp;g<br>
&nbsp;&nbsp;&nbsp;&nbsp;as_tool&nbsp;=&nbsp;runnable.<a href="#ChatVertexAI-as_tool">as_tool</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;as_tool.<a href="#ChatVertexAI-invoke">invoke</a>("b")<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.2.14</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-assign"><strong>assign</strong></a>(self, **kwargs: 'Union[Runnable[dict[str, Any], Any], Callable[[dict[str, Any]], Any], Mapping[str, Union[Runnable[dict[str, Any], Any], Callable[[dict[str, Any]], Any]]]]') -&gt; 'RunnableSerializable[Any, Any]'</dt><dd><tt>Assigns&nbsp;new&nbsp;fields&nbsp;to&nbsp;the&nbsp;dict&nbsp;output&nbsp;of&nbsp;this&nbsp;Runnable.<br>
Returns&nbsp;a&nbsp;new&nbsp;Runnable.<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_community.llms.fake&nbsp;import&nbsp;FakeStreamingListLLM<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.output_parsers&nbsp;import&nbsp;StrOutputParser<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.prompts&nbsp;import&nbsp;SystemMessagePromptTemplate<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;Runnable<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;operator&nbsp;import&nbsp;itemgetter<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompt&nbsp;=&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SystemMessagePromptTemplate.from_template("You&nbsp;are&nbsp;a&nbsp;nice&nbsp;assistant.")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;"{question}"<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;llm&nbsp;=&nbsp;FakeStreamingListLLM(responses=["foo-lish"])<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;chain:&nbsp;Runnable&nbsp;=&nbsp;prompt&nbsp;|&nbsp;llm&nbsp;|&nbsp;{"str":&nbsp;StrOutputParser()}<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;chain_with_assign&nbsp;=&nbsp;chain.<a href="#ChatVertexAI-assign">assign</a>(hello=itemgetter("str")&nbsp;|&nbsp;llm)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;print(chain_with_assign.input_schema.<a href="#ChatVertexAI-model_json_schema">model_json_schema</a>())<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;{'title':&nbsp;'PromptInput',&nbsp;'type':&nbsp;'object',&nbsp;'properties':<br>
&nbsp;&nbsp;&nbsp;&nbsp;{'question':&nbsp;{'title':&nbsp;'Question',&nbsp;'type':&nbsp;'string'}}}<br>
&nbsp;&nbsp;&nbsp;&nbsp;print(chain_with_assign.output_schema.<a href="#ChatVertexAI-model_json_schema">model_json_schema</a>())<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;{'title':&nbsp;'RunnableSequenceOutput',&nbsp;'type':&nbsp;'object',&nbsp;'properties':<br>
&nbsp;&nbsp;&nbsp;&nbsp;{'str':&nbsp;{'title':&nbsp;'Str',<br>
&nbsp;&nbsp;&nbsp;&nbsp;'type':&nbsp;'string'},&nbsp;'hello':&nbsp;{'title':&nbsp;'Hello',&nbsp;'type':&nbsp;'string'}}}</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-astream_events"><strong>astream_events</strong></a>(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, version: "Literal['v1', 'v2']" = 'v2', include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -&gt; 'AsyncIterator[StreamEvent]'</dt><dd><tt>Generate&nbsp;a&nbsp;stream&nbsp;of&nbsp;events.<br>
&nbsp;<br>
Use&nbsp;to&nbsp;create&nbsp;an&nbsp;iterator&nbsp;over&nbsp;StreamEvents&nbsp;that&nbsp;provide&nbsp;real-time&nbsp;information<br>
about&nbsp;the&nbsp;progress&nbsp;of&nbsp;the&nbsp;Runnable,&nbsp;including&nbsp;StreamEvents&nbsp;from&nbsp;intermediate<br>
results.<br>
&nbsp;<br>
A&nbsp;StreamEvent&nbsp;is&nbsp;a&nbsp;dictionary&nbsp;with&nbsp;the&nbsp;following&nbsp;schema:<br>
&nbsp;<br>
-&nbsp;``event``:&nbsp;**str**&nbsp;-&nbsp;Event&nbsp;names&nbsp;are&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;format:&nbsp;on_[runnable_type]_(start|stream|end).<br>
-&nbsp;``name``:&nbsp;**str**&nbsp;-&nbsp;The&nbsp;name&nbsp;of&nbsp;the&nbsp;Runnable&nbsp;that&nbsp;generated&nbsp;the&nbsp;event.<br>
-&nbsp;``run_id``:&nbsp;**str**&nbsp;-&nbsp;randomly&nbsp;generated&nbsp;ID&nbsp;associated&nbsp;with&nbsp;the&nbsp;given&nbsp;execution&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;Runnable&nbsp;that&nbsp;emitted&nbsp;the&nbsp;event.<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;child&nbsp;Runnable&nbsp;that&nbsp;gets&nbsp;invoked&nbsp;as&nbsp;part&nbsp;of&nbsp;the&nbsp;execution&nbsp;of&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;parent&nbsp;Runnable&nbsp;is&nbsp;assigned&nbsp;its&nbsp;own&nbsp;unique&nbsp;ID.<br>
-&nbsp;``parent_ids``:&nbsp;**List[str]**&nbsp;-&nbsp;The&nbsp;IDs&nbsp;of&nbsp;the&nbsp;parent&nbsp;runnables&nbsp;that<br>
&nbsp;&nbsp;&nbsp;&nbsp;generated&nbsp;the&nbsp;event.&nbsp;The&nbsp;root&nbsp;Runnable&nbsp;will&nbsp;have&nbsp;an&nbsp;empty&nbsp;list.<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;order&nbsp;of&nbsp;the&nbsp;parent&nbsp;IDs&nbsp;is&nbsp;from&nbsp;the&nbsp;root&nbsp;to&nbsp;the&nbsp;immediate&nbsp;parent.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Only&nbsp;available&nbsp;for&nbsp;v2&nbsp;version&nbsp;of&nbsp;the&nbsp;API.&nbsp;The&nbsp;v1&nbsp;version&nbsp;of&nbsp;the&nbsp;API<br>
&nbsp;&nbsp;&nbsp;&nbsp;will&nbsp;return&nbsp;an&nbsp;empty&nbsp;list.<br>
-&nbsp;``tags``:&nbsp;**Optional[List[str]]**&nbsp;-&nbsp;The&nbsp;tags&nbsp;of&nbsp;the&nbsp;Runnable&nbsp;that&nbsp;generated<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;event.<br>
-&nbsp;``metadata``:&nbsp;**Optional[Dict[str,&nbsp;Any]]**&nbsp;-&nbsp;The&nbsp;metadata&nbsp;of&nbsp;the&nbsp;Runnable<br>
&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;generated&nbsp;the&nbsp;event.<br>
-&nbsp;``data``:&nbsp;**Dict[str,&nbsp;Any]**<br>
&nbsp;<br>
&nbsp;<br>
Below&nbsp;is&nbsp;a&nbsp;table&nbsp;that&nbsp;illustrates&nbsp;some&nbsp;events&nbsp;that&nbsp;might&nbsp;be&nbsp;emitted&nbsp;by&nbsp;various<br>
chains.&nbsp;Metadata&nbsp;fields&nbsp;have&nbsp;been&nbsp;omitted&nbsp;from&nbsp;the&nbsp;table&nbsp;for&nbsp;brevity.<br>
Chain&nbsp;definitions&nbsp;have&nbsp;been&nbsp;included&nbsp;after&nbsp;the&nbsp;table.<br>
&nbsp;<br>
**ATTENTION**&nbsp;This&nbsp;reference&nbsp;table&nbsp;is&nbsp;for&nbsp;the&nbsp;V2&nbsp;version&nbsp;of&nbsp;the&nbsp;schema.<br>
&nbsp;<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;event&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;name&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;chunk&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;input&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;output&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+======================+==================+=================================+===============================================+=================================================+<br>
|&nbsp;on_chat_model_start&nbsp;&nbsp;|&nbsp;[model&nbsp;name]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;{"messages":&nbsp;[[SystemMessage,&nbsp;HumanMessage]]}&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_chat_model_stream&nbsp;|&nbsp;[model&nbsp;name]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;AIMessageChunk(content="hello")&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_chat_model_end&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;[model&nbsp;name]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;{"messages":&nbsp;[[SystemMessage,&nbsp;HumanMessage]]}&nbsp;|&nbsp;AIMessageChunk(content="hello&nbsp;world")&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_llm_start&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;[model&nbsp;name]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;{'input':&nbsp;'hello'}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_llm_stream&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;[model&nbsp;name]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;'Hello'&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_llm_end&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;[model&nbsp;name]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;'Hello&nbsp;human!'&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_chain_start&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;format_docs&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_chain_stream&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;format_docs&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;"hello&nbsp;world!,&nbsp;goodbye&nbsp;world!"&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_chain_end&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;format_docs&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;[Document(...)]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;"hello&nbsp;world!,&nbsp;goodbye&nbsp;world!"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_tool_start&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;some_tool&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;{"x":&nbsp;1,&nbsp;"y":&nbsp;"2"}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_tool_end&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;some_tool&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;{"x":&nbsp;1,&nbsp;"y":&nbsp;"2"}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_retriever_start&nbsp;&nbsp;&nbsp;|&nbsp;[retriever&nbsp;name]&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;{"query":&nbsp;"hello"}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_retriever_end&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;[retriever&nbsp;name]&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;{"query":&nbsp;"hello"}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;[Document(...),&nbsp;..]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_prompt_start&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;[template_name]&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;{"question":&nbsp;"hello"}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
|&nbsp;on_prompt_end&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;[template_name]&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;{"question":&nbsp;"hello"}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;ChatPromptValue(messages:&nbsp;[SystemMessage,&nbsp;...])&nbsp;|<br>
+----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+<br>
&nbsp;<br>
In&nbsp;addition&nbsp;to&nbsp;the&nbsp;standard&nbsp;events,&nbsp;users&nbsp;can&nbsp;also&nbsp;dispatch&nbsp;custom&nbsp;events&nbsp;(see&nbsp;example&nbsp;below).<br>
&nbsp;<br>
Custom&nbsp;events&nbsp;will&nbsp;be&nbsp;only&nbsp;be&nbsp;surfaced&nbsp;with&nbsp;in&nbsp;the&nbsp;`v2`&nbsp;version&nbsp;of&nbsp;the&nbsp;API!<br>
&nbsp;<br>
A&nbsp;custom&nbsp;event&nbsp;has&nbsp;following&nbsp;format:<br>
&nbsp;<br>
+-----------+------+-----------------------------------------------------------------------------------------------------------+<br>
|&nbsp;Attribute&nbsp;|&nbsp;Type&nbsp;|&nbsp;Description&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+===========+======+===========================================================================================================+<br>
|&nbsp;name&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;str&nbsp;&nbsp;|&nbsp;A&nbsp;user&nbsp;defined&nbsp;name&nbsp;for&nbsp;the&nbsp;event.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
+-----------+------+-----------------------------------------------------------------------------------------------------------+<br>
|&nbsp;data&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;Any&nbsp;&nbsp;|&nbsp;The&nbsp;data&nbsp;associated&nbsp;with&nbsp;the&nbsp;event.&nbsp;This&nbsp;can&nbsp;be&nbsp;anything,&nbsp;though&nbsp;we&nbsp;suggest&nbsp;making&nbsp;it&nbsp;JSON&nbsp;serializable.&nbsp;&nbsp;|<br>
+-----------+------+-----------------------------------------------------------------------------------------------------------+<br>
&nbsp;<br>
Here&nbsp;are&nbsp;declarations&nbsp;associated&nbsp;with&nbsp;the&nbsp;standard&nbsp;events&nbsp;shown&nbsp;above:<br>
&nbsp;<br>
`format_docs`:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;format_docs(docs:&nbsp;List[Document])&nbsp;-&gt;&nbsp;str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'''Format&nbsp;the&nbsp;docs.'''<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;",&nbsp;".join([doc.page_content&nbsp;for&nbsp;doc&nbsp;in&nbsp;docs])<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;format_docs&nbsp;=&nbsp;RunnableLambda(format_docs)<br>
&nbsp;<br>
`some_tool`:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;@tool<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;some_tool(x:&nbsp;int,&nbsp;y:&nbsp;str)&nbsp;-&gt;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'''Some_tool.'''<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;{"x":&nbsp;x,&nbsp;"y":&nbsp;y}<br>
&nbsp;<br>
`prompt`:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;template&nbsp;=&nbsp;ChatPromptTemplate.from_messages(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[("system",&nbsp;"You&nbsp;are&nbsp;Cat&nbsp;Agent&nbsp;007"),&nbsp;("human",&nbsp;"{question}")]<br>
&nbsp;&nbsp;&nbsp;&nbsp;).<a href="#ChatVertexAI-with_config">with_config</a>({"run_name":&nbsp;"my_template",&nbsp;"tags":&nbsp;["my_template"]})<br>
&nbsp;<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;async&nbsp;def&nbsp;reverse(s:&nbsp;str)&nbsp;-&gt;&nbsp;str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;s[::-1]<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;chain&nbsp;=&nbsp;RunnableLambda(func=reverse)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;events&nbsp;=&nbsp;[<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;event&nbsp;async&nbsp;for&nbsp;event&nbsp;in&nbsp;chain.<a href="#ChatVertexAI-astream_events">astream_events</a>("hello",&nbsp;version="v2")<br>
&nbsp;&nbsp;&nbsp;&nbsp;]<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;will&nbsp;produce&nbsp;the&nbsp;following&nbsp;events&nbsp;(run_id,&nbsp;and&nbsp;parent_ids<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;has&nbsp;been&nbsp;omitted&nbsp;for&nbsp;brevity):<br>
&nbsp;&nbsp;&nbsp;&nbsp;[<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"data":&nbsp;{"input":&nbsp;"hello"},<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"event":&nbsp;"on_chain_start",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"metadata":&nbsp;{},<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"reverse",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"tags":&nbsp;[],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"data":&nbsp;{"chunk":&nbsp;"olleh"},<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"event":&nbsp;"on_chain_stream",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"metadata":&nbsp;{},<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"reverse",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"tags":&nbsp;[],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"data":&nbsp;{"output":&nbsp;"olleh"},<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"event":&nbsp;"on_chain_end",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"metadata":&nbsp;{},<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"reverse",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"tags":&nbsp;[],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},<br>
&nbsp;&nbsp;&nbsp;&nbsp;]<br>
&nbsp;<br>
&nbsp;<br>
Example:&nbsp;Dispatch&nbsp;Custom&nbsp;Event<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.callbacks.manager&nbsp;import&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;adispatch_custom_event,<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda,&nbsp;RunnableConfig<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;asyncio<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;async&nbsp;def&nbsp;slow_thing(some_input:&nbsp;str,&nbsp;config:&nbsp;RunnableConfig)&nbsp;-&gt;&nbsp;str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Do&nbsp;something&nbsp;that&nbsp;takes&nbsp;a&nbsp;long&nbsp;time."""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;asyncio.sleep(1)&nbsp;#&nbsp;Placeholder&nbsp;for&nbsp;some&nbsp;slow&nbsp;operation<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;adispatch_custom_event(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"progress_event",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{"message":&nbsp;"Finished&nbsp;step&nbsp;1&nbsp;of&nbsp;3"},<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;config=config&nbsp;#&nbsp;Must&nbsp;be&nbsp;included&nbsp;for&nbsp;python&nbsp;&lt;&nbsp;3.10<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;asyncio.sleep(1)&nbsp;#&nbsp;Placeholder&nbsp;for&nbsp;some&nbsp;slow&nbsp;operation<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;adispatch_custom_event(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"progress_event",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{"message":&nbsp;"Finished&nbsp;step&nbsp;2&nbsp;of&nbsp;3"},<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;config=config&nbsp;#&nbsp;Must&nbsp;be&nbsp;included&nbsp;for&nbsp;python&nbsp;&lt;&nbsp;3.10<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;asyncio.sleep(1)&nbsp;#&nbsp;Placeholder&nbsp;for&nbsp;some&nbsp;slow&nbsp;operation<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;"Done"<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;slow_thing&nbsp;=&nbsp;RunnableLambda(slow_thing)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;async&nbsp;for&nbsp;event&nbsp;in&nbsp;slow_thing.<a href="#ChatVertexAI-astream_events">astream_events</a>("some_input",&nbsp;version="v2"):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(event)<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input:&nbsp;The&nbsp;input&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;The&nbsp;config&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;version:&nbsp;The&nbsp;version&nbsp;of&nbsp;the&nbsp;schema&nbsp;to&nbsp;use&nbsp;either&nbsp;`v2`&nbsp;or&nbsp;`v1`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Users&nbsp;should&nbsp;use&nbsp;`v2`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`v1`&nbsp;is&nbsp;for&nbsp;backwards&nbsp;compatibility&nbsp;and&nbsp;will&nbsp;be&nbsp;deprecated<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;0.4.0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No&nbsp;default&nbsp;will&nbsp;be&nbsp;assigned&nbsp;until&nbsp;the&nbsp;API&nbsp;is&nbsp;stabilized.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;custom&nbsp;events&nbsp;will&nbsp;only&nbsp;be&nbsp;surfaced&nbsp;in&nbsp;`v2`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;include_names:&nbsp;Only&nbsp;include&nbsp;events&nbsp;from&nbsp;runnables&nbsp;with&nbsp;matching&nbsp;names.<br>
&nbsp;&nbsp;&nbsp;&nbsp;include_types:&nbsp;Only&nbsp;include&nbsp;events&nbsp;from&nbsp;runnables&nbsp;with&nbsp;matching&nbsp;types.<br>
&nbsp;&nbsp;&nbsp;&nbsp;include_tags:&nbsp;Only&nbsp;include&nbsp;events&nbsp;from&nbsp;runnables&nbsp;with&nbsp;matching&nbsp;tags.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_names:&nbsp;Exclude&nbsp;events&nbsp;from&nbsp;runnables&nbsp;with&nbsp;matching&nbsp;names.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_types:&nbsp;Exclude&nbsp;events&nbsp;from&nbsp;runnables&nbsp;with&nbsp;matching&nbsp;types.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_tags:&nbsp;Exclude&nbsp;events&nbsp;from&nbsp;runnables&nbsp;with&nbsp;matching&nbsp;tags.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs:&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;These&nbsp;will&nbsp;be&nbsp;passed&nbsp;to&nbsp;astream_log&nbsp;as&nbsp;this&nbsp;implementation<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;astream_events&nbsp;is&nbsp;built&nbsp;on&nbsp;top&nbsp;of&nbsp;astream_log.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;An&nbsp;async&nbsp;stream&nbsp;of&nbsp;StreamEvents.<br>
&nbsp;<br>
Raises:<br>
&nbsp;&nbsp;&nbsp;&nbsp;NotImplementedError:&nbsp;If&nbsp;the&nbsp;version&nbsp;is&nbsp;not&nbsp;`v1`&nbsp;or&nbsp;`v2`.</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-astream_log"><strong>astream_log</strong></a>(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, diff: 'bool' = True, with_streamed_output_list: 'bool' = True, include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -&gt; 'Union[AsyncIterator[RunLogPatch], AsyncIterator[RunLog]]'</dt><dd><tt>Stream&nbsp;all&nbsp;output&nbsp;from&nbsp;a&nbsp;Runnable,&nbsp;as&nbsp;reported&nbsp;to&nbsp;the&nbsp;callback&nbsp;system.<br>
This&nbsp;includes&nbsp;all&nbsp;inner&nbsp;runs&nbsp;of&nbsp;LLMs,&nbsp;Retrievers,&nbsp;Tools,&nbsp;etc.<br>
&nbsp;<br>
Output&nbsp;is&nbsp;streamed&nbsp;as&nbsp;Log&nbsp;objects,&nbsp;which&nbsp;include&nbsp;a&nbsp;list&nbsp;of<br>
Jsonpatch&nbsp;ops&nbsp;that&nbsp;describe&nbsp;how&nbsp;the&nbsp;state&nbsp;of&nbsp;the&nbsp;run&nbsp;has&nbsp;changed&nbsp;in&nbsp;each<br>
step,&nbsp;and&nbsp;the&nbsp;final&nbsp;state&nbsp;of&nbsp;the&nbsp;run.<br>
&nbsp;<br>
The&nbsp;Jsonpatch&nbsp;ops&nbsp;can&nbsp;be&nbsp;applied&nbsp;in&nbsp;order&nbsp;to&nbsp;construct&nbsp;state.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input:&nbsp;The&nbsp;input&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;The&nbsp;config&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;diff:&nbsp;Whether&nbsp;to&nbsp;yield&nbsp;diffs&nbsp;between&nbsp;each&nbsp;step&nbsp;or&nbsp;the&nbsp;current&nbsp;state.<br>
&nbsp;&nbsp;&nbsp;&nbsp;with_streamed_output_list:&nbsp;Whether&nbsp;to&nbsp;yield&nbsp;the&nbsp;streamed_output&nbsp;list.<br>
&nbsp;&nbsp;&nbsp;&nbsp;include_names:&nbsp;Only&nbsp;include&nbsp;logs&nbsp;with&nbsp;these&nbsp;names.<br>
&nbsp;&nbsp;&nbsp;&nbsp;include_types:&nbsp;Only&nbsp;include&nbsp;logs&nbsp;with&nbsp;these&nbsp;types.<br>
&nbsp;&nbsp;&nbsp;&nbsp;include_tags:&nbsp;Only&nbsp;include&nbsp;logs&nbsp;with&nbsp;these&nbsp;tags.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_names:&nbsp;Exclude&nbsp;logs&nbsp;with&nbsp;these&nbsp;names.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_types:&nbsp;Exclude&nbsp;logs&nbsp;with&nbsp;these&nbsp;types.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exclude_tags:&nbsp;Exclude&nbsp;logs&nbsp;with&nbsp;these&nbsp;tags.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs:&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;RunLogPatch&nbsp;or&nbsp;RunLog&nbsp;object.</tt></dd></dl>

<dl><dt>async <a name="ChatVertexAI-atransform"><strong>atransform</strong></a>(self, input: 'AsyncIterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -&gt; 'AsyncIterator[Output]'</dt><dd><tt>Default&nbsp;implementation&nbsp;of&nbsp;atransform,&nbsp;which&nbsp;buffers&nbsp;input&nbsp;and&nbsp;calls&nbsp;astream.<br>
Subclasses&nbsp;should&nbsp;override&nbsp;this&nbsp;method&nbsp;if&nbsp;they&nbsp;can&nbsp;start&nbsp;producing&nbsp;output&nbsp;while<br>
input&nbsp;is&nbsp;still&nbsp;being&nbsp;generated.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input:&nbsp;An&nbsp;async&nbsp;iterator&nbsp;of&nbsp;inputs&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;The&nbsp;config&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;Runnable.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs:&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;output&nbsp;of&nbsp;the&nbsp;Runnable.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-batch"><strong>batch</strong></a>(self, inputs: 'list[Input]', config: 'Optional[Union[RunnableConfig, list[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -&gt; 'list[Output]'</dt><dd><tt>Default&nbsp;implementation&nbsp;runs&nbsp;invoke&nbsp;in&nbsp;parallel&nbsp;using&nbsp;a&nbsp;thread&nbsp;pool&nbsp;executor.<br>
&nbsp;<br>
The&nbsp;default&nbsp;implementation&nbsp;of&nbsp;batch&nbsp;works&nbsp;well&nbsp;for&nbsp;IO&nbsp;bound&nbsp;runnables.<br>
&nbsp;<br>
Subclasses&nbsp;should&nbsp;override&nbsp;this&nbsp;method&nbsp;if&nbsp;they&nbsp;can&nbsp;batch&nbsp;more&nbsp;efficiently;<br>
e.g.,&nbsp;if&nbsp;the&nbsp;underlying&nbsp;Runnable&nbsp;uses&nbsp;an&nbsp;API&nbsp;which&nbsp;supports&nbsp;a&nbsp;batch&nbsp;mode.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-batch_as_completed"><strong>batch_as_completed</strong></a>(self, inputs: 'Sequence[Input]', config: 'Optional[Union[RunnableConfig, Sequence[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -&gt; 'Iterator[tuple[int, Union[Output, Exception]]]'</dt><dd><tt>Run&nbsp;invoke&nbsp;in&nbsp;parallel&nbsp;on&nbsp;a&nbsp;list&nbsp;of&nbsp;inputs,<br>
yielding&nbsp;results&nbsp;as&nbsp;they&nbsp;complete.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-bind"><strong>bind</strong></a>(self, **kwargs: 'Any') -&gt; 'Runnable[Input, Output]'</dt><dd><tt>Bind&nbsp;arguments&nbsp;to&nbsp;a&nbsp;Runnable,&nbsp;returning&nbsp;a&nbsp;new&nbsp;Runnable.<br>
&nbsp;<br>
Useful&nbsp;when&nbsp;a&nbsp;Runnable&nbsp;in&nbsp;a&nbsp;chain&nbsp;requires&nbsp;an&nbsp;argument&nbsp;that&nbsp;is&nbsp;not<br>
in&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;previous&nbsp;Runnable&nbsp;or&nbsp;included&nbsp;in&nbsp;the&nbsp;user&nbsp;input.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs:&nbsp;The&nbsp;arguments&nbsp;to&nbsp;bind&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;with&nbsp;the&nbsp;arguments&nbsp;bound.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_community.chat_models&nbsp;import&nbsp;ChatOllama<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.output_parsers&nbsp;import&nbsp;StrOutputParser<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;llm&nbsp;=&nbsp;ChatOllama(model='llama2')<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;Without&nbsp;bind.<br>
&nbsp;&nbsp;&nbsp;&nbsp;chain&nbsp;=&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;llm<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;StrOutputParser()<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;chain.<a href="#ChatVertexAI-invoke">invoke</a>("Repeat&nbsp;quoted&nbsp;words&nbsp;exactly:&nbsp;'One&nbsp;two&nbsp;three&nbsp;four&nbsp;five.'")<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;Output&nbsp;is&nbsp;'One&nbsp;two&nbsp;three&nbsp;four&nbsp;five.'<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;With&nbsp;bind.<br>
&nbsp;&nbsp;&nbsp;&nbsp;chain&nbsp;=&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;llm.<a href="#ChatVertexAI-bind">bind</a>(stop=["three"])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;StrOutputParser()<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;chain.<a href="#ChatVertexAI-invoke">invoke</a>("Repeat&nbsp;quoted&nbsp;words&nbsp;exactly:&nbsp;'One&nbsp;two&nbsp;three&nbsp;four&nbsp;five.'")<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;Output&nbsp;is&nbsp;'One&nbsp;two'</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-config_schema"><strong>config_schema</strong></a>(self, *, include: 'Optional[Sequence[str]]' = None) -&gt; 'type[BaseModel]'</dt><dd><tt>The&nbsp;type&nbsp;of&nbsp;config&nbsp;this&nbsp;Runnable&nbsp;accepts&nbsp;specified&nbsp;as&nbsp;a&nbsp;pydantic&nbsp;model.<br>
&nbsp;<br>
To&nbsp;mark&nbsp;a&nbsp;field&nbsp;as&nbsp;configurable,&nbsp;see&nbsp;the&nbsp;`configurable_fields`<br>
and&nbsp;`configurable_alternatives`&nbsp;methods.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;include:&nbsp;A&nbsp;list&nbsp;of&nbsp;fields&nbsp;to&nbsp;include&nbsp;in&nbsp;the&nbsp;config&nbsp;schema.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;pydantic&nbsp;model&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;validate&nbsp;config.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-get_config_jsonschema"><strong>get_config_jsonschema</strong></a>(self, *, include: 'Optional[Sequence[str]]' = None) -&gt; 'dict[str, Any]'</dt><dd><tt>Get&nbsp;a&nbsp;JSON&nbsp;schema&nbsp;that&nbsp;represents&nbsp;the&nbsp;config&nbsp;of&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;include:&nbsp;A&nbsp;list&nbsp;of&nbsp;fields&nbsp;to&nbsp;include&nbsp;in&nbsp;the&nbsp;config&nbsp;schema.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;JSON&nbsp;schema&nbsp;that&nbsp;represents&nbsp;the&nbsp;config&nbsp;of&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.3.0</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-get_graph"><strong>get_graph</strong></a>(self, config: 'Optional[RunnableConfig]' = None) -&gt; 'Graph'</dt><dd><tt>Return&nbsp;a&nbsp;graph&nbsp;representation&nbsp;of&nbsp;this&nbsp;Runnable.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-get_input_jsonschema"><strong>get_input_jsonschema</strong></a>(self, config: 'Optional[RunnableConfig]' = None) -&gt; 'dict[str, Any]'</dt><dd><tt>Get&nbsp;a&nbsp;JSON&nbsp;schema&nbsp;that&nbsp;represents&nbsp;the&nbsp;input&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;A&nbsp;config&nbsp;to&nbsp;use&nbsp;when&nbsp;generating&nbsp;the&nbsp;schema.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;JSON&nbsp;schema&nbsp;that&nbsp;represents&nbsp;the&nbsp;input&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;add_one(x:&nbsp;int)&nbsp;-&gt;&nbsp;int:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;x&nbsp;+&nbsp;1<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runnable&nbsp;=&nbsp;RunnableLambda(add_one)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(runnable.<a href="#ChatVertexAI-get_input_jsonschema">get_input_jsonschema</a>())<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.3.0</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-get_input_schema"><strong>get_input_schema</strong></a>(self, config: 'Optional[RunnableConfig]' = None) -&gt; 'type[BaseModel]'</dt><dd><tt>Get&nbsp;a&nbsp;pydantic&nbsp;model&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;validate&nbsp;input&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Runnables&nbsp;that&nbsp;leverage&nbsp;the&nbsp;configurable_fields&nbsp;and&nbsp;configurable_alternatives<br>
methods&nbsp;will&nbsp;have&nbsp;a&nbsp;dynamic&nbsp;input&nbsp;schema&nbsp;that&nbsp;depends&nbsp;on&nbsp;which<br>
configuration&nbsp;the&nbsp;Runnable&nbsp;is&nbsp;invoked&nbsp;with.<br>
&nbsp;<br>
This&nbsp;method&nbsp;allows&nbsp;to&nbsp;get&nbsp;an&nbsp;input&nbsp;schema&nbsp;for&nbsp;a&nbsp;specific&nbsp;configuration.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;A&nbsp;config&nbsp;to&nbsp;use&nbsp;when&nbsp;generating&nbsp;the&nbsp;schema.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;pydantic&nbsp;model&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;validate&nbsp;input.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-get_name"><strong>get_name</strong></a>(self, suffix: 'Optional[str]' = None, *, name: 'Optional[str]' = None) -&gt; 'str'</dt><dd><tt>Get&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;Runnable.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-get_output_jsonschema"><strong>get_output_jsonschema</strong></a>(self, config: 'Optional[RunnableConfig]' = None) -&gt; 'dict[str, Any]'</dt><dd><tt>Get&nbsp;a&nbsp;JSON&nbsp;schema&nbsp;that&nbsp;represents&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;A&nbsp;config&nbsp;to&nbsp;use&nbsp;when&nbsp;generating&nbsp;the&nbsp;schema.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;JSON&nbsp;schema&nbsp;that&nbsp;represents&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;add_one(x:&nbsp;int)&nbsp;-&gt;&nbsp;int:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;x&nbsp;+&nbsp;1<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runnable&nbsp;=&nbsp;RunnableLambda(add_one)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(runnable.<a href="#ChatVertexAI-get_output_jsonschema">get_output_jsonschema</a>())<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.3.0</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-get_output_schema"><strong>get_output_schema</strong></a>(self, config: 'Optional[RunnableConfig]' = None) -&gt; 'type[BaseModel]'</dt><dd><tt>Get&nbsp;a&nbsp;pydantic&nbsp;model&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;validate&nbsp;output&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Runnables&nbsp;that&nbsp;leverage&nbsp;the&nbsp;configurable_fields&nbsp;and&nbsp;configurable_alternatives<br>
methods&nbsp;will&nbsp;have&nbsp;a&nbsp;dynamic&nbsp;output&nbsp;schema&nbsp;that&nbsp;depends&nbsp;on&nbsp;which<br>
configuration&nbsp;the&nbsp;Runnable&nbsp;is&nbsp;invoked&nbsp;with.<br>
&nbsp;<br>
This&nbsp;method&nbsp;allows&nbsp;to&nbsp;get&nbsp;an&nbsp;output&nbsp;schema&nbsp;for&nbsp;a&nbsp;specific&nbsp;configuration.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;A&nbsp;config&nbsp;to&nbsp;use&nbsp;when&nbsp;generating&nbsp;the&nbsp;schema.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;pydantic&nbsp;model&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;validate&nbsp;output.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-get_prompts"><strong>get_prompts</strong></a>(self, config: 'Optional[RunnableConfig]' = None) -&gt; 'list[BasePromptTemplate]'</dt><dd><tt>Return&nbsp;a&nbsp;list&nbsp;of&nbsp;prompts&nbsp;used&nbsp;by&nbsp;this&nbsp;Runnable.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-map"><strong>map</strong></a>(self) -&gt; 'Runnable[list[Input], list[Output]]'</dt><dd><tt>Return&nbsp;a&nbsp;new&nbsp;Runnable&nbsp;that&nbsp;maps&nbsp;a&nbsp;list&nbsp;of&nbsp;inputs&nbsp;to&nbsp;a&nbsp;list&nbsp;of&nbsp;outputs,<br>
by&nbsp;calling&nbsp;<a href="#ChatVertexAI-invoke">invoke</a>()&nbsp;with&nbsp;each&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;that&nbsp;maps&nbsp;a&nbsp;list&nbsp;of&nbsp;inputs&nbsp;to&nbsp;a&nbsp;list&nbsp;of&nbsp;outputs.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;_lambda(x:&nbsp;int)&nbsp;-&gt;&nbsp;int:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;x&nbsp;+&nbsp;1<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runnable&nbsp;=&nbsp;RunnableLambda(_lambda)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(runnable.<a href="#ChatVertexAI-map">map</a>().<a href="#ChatVertexAI-invoke">invoke</a>([1,&nbsp;2,&nbsp;3]))&nbsp;#&nbsp;[2,&nbsp;3,&nbsp;4]</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-pick"><strong>pick</strong></a>(self, keys: 'Union[str, list[str]]') -&gt; 'RunnableSerializable[Any, Any]'</dt><dd><tt>Pick&nbsp;keys&nbsp;from&nbsp;the&nbsp;output&nbsp;dict&nbsp;of&nbsp;this&nbsp;Runnable.<br>
&nbsp;<br>
Pick&nbsp;single&nbsp;key:<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;json<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda,&nbsp;RunnableMap<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;as_str&nbsp;=&nbsp;RunnableLambda(str)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;as_json&nbsp;=&nbsp;RunnableLambda(json.loads)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain&nbsp;=&nbsp;RunnableMap(str=as_str,&nbsp;json=as_json)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain.<a href="#ChatVertexAI-invoke">invoke</a>("[1,&nbsp;2,&nbsp;3]")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;-&gt;&nbsp;{"str":&nbsp;"[1,&nbsp;2,&nbsp;3]",&nbsp;"json":&nbsp;[1,&nbsp;2,&nbsp;3]}<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;json_only_chain&nbsp;=&nbsp;chain.<a href="#ChatVertexAI-pick">pick</a>("json")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;json_only_chain.<a href="#ChatVertexAI-invoke">invoke</a>("[1,&nbsp;2,&nbsp;3]")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;-&gt;&nbsp;[1,&nbsp;2,&nbsp;3]<br>
&nbsp;<br>
Pick&nbsp;list&nbsp;of&nbsp;keys:<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;typing&nbsp;import&nbsp;Any<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;json<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda,&nbsp;RunnableMap<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;as_str&nbsp;=&nbsp;RunnableLambda(str)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;as_json&nbsp;=&nbsp;RunnableLambda(json.loads)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;as_bytes(x:&nbsp;Any)&nbsp;-&gt;&nbsp;bytes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;bytes(x,&nbsp;"utf-8")<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain&nbsp;=&nbsp;RunnableMap(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;str=as_str,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;json=as_json,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytes=RunnableLambda(as_bytes)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chain.<a href="#ChatVertexAI-invoke">invoke</a>("[1,&nbsp;2,&nbsp;3]")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;-&gt;&nbsp;{"str":&nbsp;"[1,&nbsp;2,&nbsp;3]",&nbsp;"json":&nbsp;[1,&nbsp;2,&nbsp;3],&nbsp;"bytes":&nbsp;b"[1,&nbsp;2,&nbsp;3]"}<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;json_and_bytes_chain&nbsp;=&nbsp;chain.<a href="#ChatVertexAI-pick">pick</a>(["json",&nbsp;"bytes"])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;json_and_bytes_chain.<a href="#ChatVertexAI-invoke">invoke</a>("[1,&nbsp;2,&nbsp;3]")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;-&gt;&nbsp;{"json":&nbsp;[1,&nbsp;2,&nbsp;3],&nbsp;"bytes":&nbsp;b"[1,&nbsp;2,&nbsp;3]"}</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-pipe"><strong>pipe</strong></a>(self, *others: 'Union[Runnable[Any, Other], Callable[[Any], Other]]', name: 'Optional[str]' = None) -&gt; 'RunnableSerializable[Input, Other]'</dt><dd><tt>Compose&nbsp;this&nbsp;Runnable&nbsp;with&nbsp;Runnable-like&nbsp;objects&nbsp;to&nbsp;make&nbsp;a&nbsp;RunnableSequence.<br>
&nbsp;<br>
Equivalent&nbsp;to&nbsp;`RunnableSequence(self,&nbsp;*others)`&nbsp;or&nbsp;`self&nbsp;|&nbsp;others[0]&nbsp;|&nbsp;...`<br>
&nbsp;<br>
Example:<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;add_one(x:&nbsp;int)&nbsp;-&gt;&nbsp;int:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;x&nbsp;+&nbsp;1<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;mul_two(x:&nbsp;int)&nbsp;-&gt;&nbsp;int:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;x&nbsp;*&nbsp;2<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runnable_1&nbsp;=&nbsp;RunnableLambda(add_one)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runnable_2&nbsp;=&nbsp;RunnableLambda(mul_two)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sequence&nbsp;=&nbsp;runnable_1.<a href="#ChatVertexAI-pipe">pipe</a>(runnable_2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;Or&nbsp;equivalently:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;sequence&nbsp;=&nbsp;runnable_1&nbsp;|&nbsp;runnable_2<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;sequence&nbsp;=&nbsp;RunnableSequence(first=runnable_1,&nbsp;last=runnable_2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sequence.<a href="#ChatVertexAI-invoke">invoke</a>(1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;sequence.<a href="#ChatVertexAI-ainvoke">ainvoke</a>(1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;-&gt;&nbsp;4<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sequence.<a href="#ChatVertexAI-batch">batch</a>([1,&nbsp;2,&nbsp;3])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;sequence.<a href="#ChatVertexAI-abatch">abatch</a>([1,&nbsp;2,&nbsp;3])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;-&gt;&nbsp;[4,&nbsp;6,&nbsp;8]</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-transform"><strong>transform</strong></a>(self, input: 'Iterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -&gt; 'Iterator[Output]'</dt><dd><tt>Default&nbsp;implementation&nbsp;of&nbsp;transform,&nbsp;which&nbsp;buffers&nbsp;input&nbsp;and&nbsp;calls&nbsp;astream.<br>
&nbsp;<br>
Subclasses&nbsp;should&nbsp;override&nbsp;this&nbsp;method&nbsp;if&nbsp;they&nbsp;can&nbsp;start&nbsp;producing&nbsp;output&nbsp;while<br>
input&nbsp;is&nbsp;still&nbsp;being&nbsp;generated.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input:&nbsp;An&nbsp;iterator&nbsp;of&nbsp;inputs&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;The&nbsp;config&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;Runnable.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs:&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;output&nbsp;of&nbsp;the&nbsp;Runnable.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-with_alisteners"><strong>with_alisteners</strong></a>(self, *, on_start: 'Optional[AsyncListener]' = None, on_end: 'Optional[AsyncListener]' = None, on_error: 'Optional[AsyncListener]' = None) -&gt; 'Runnable[Input, Output]'</dt><dd><tt>Bind&nbsp;async&nbsp;lifecycle&nbsp;listeners&nbsp;to&nbsp;a&nbsp;Runnable,&nbsp;returning&nbsp;a&nbsp;new&nbsp;Runnable.<br>
&nbsp;<br>
on_start:&nbsp;Asynchronously&nbsp;called&nbsp;before&nbsp;the&nbsp;Runnable&nbsp;starts&nbsp;running.<br>
on_end:&nbsp;Asynchronously&nbsp;called&nbsp;after&nbsp;the&nbsp;Runnable&nbsp;finishes&nbsp;running.<br>
on_error:&nbsp;Asynchronously&nbsp;called&nbsp;if&nbsp;the&nbsp;Runnable&nbsp;throws&nbsp;an&nbsp;error.<br>
&nbsp;<br>
The&nbsp;Run&nbsp;object&nbsp;contains&nbsp;information&nbsp;about&nbsp;the&nbsp;run,&nbsp;including&nbsp;its&nbsp;id,<br>
type,&nbsp;input,&nbsp;output,&nbsp;error,&nbsp;start_time,&nbsp;end_time,&nbsp;and&nbsp;any&nbsp;tags&nbsp;or&nbsp;metadata<br>
added&nbsp;to&nbsp;the&nbsp;run.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;on_start:&nbsp;Asynchronously&nbsp;called&nbsp;before&nbsp;the&nbsp;Runnable&nbsp;starts&nbsp;running.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;on_end:&nbsp;Asynchronously&nbsp;called&nbsp;after&nbsp;the&nbsp;Runnable&nbsp;finishes&nbsp;running.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;on_error:&nbsp;Asynchronously&nbsp;called&nbsp;if&nbsp;the&nbsp;Runnable&nbsp;throws&nbsp;an&nbsp;error.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;with&nbsp;the&nbsp;listeners&nbsp;bound.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda,&nbsp;Runnable<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;datetime&nbsp;import&nbsp;datetime,&nbsp;timezone<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;time<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;asyncio<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;format_t(timestamp:&nbsp;float)&nbsp;-&gt;&nbsp;str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;datetime.fromtimestamp(timestamp,&nbsp;tz=timezone.utc).isoformat()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;async&nbsp;def&nbsp;test_runnable(time_to_sleep&nbsp;:&nbsp;int):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(f"Runnable[{time_to_sleep}s]:&nbsp;starts&nbsp;at&nbsp;{format_t(time.time())}")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;asyncio.sleep(time_to_sleep)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(f"Runnable[{time_to_sleep}s]:&nbsp;ends&nbsp;at&nbsp;{format_t(time.time())}")<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;async&nbsp;def&nbsp;fn_start(run_obj&nbsp;:&nbsp;Runnable):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(f"on&nbsp;start&nbsp;callback&nbsp;starts&nbsp;at&nbsp;{format_t(time.time())}")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;asyncio.sleep(3)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(f"on&nbsp;start&nbsp;callback&nbsp;ends&nbsp;at&nbsp;{format_t(time.time())}")<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;async&nbsp;def&nbsp;fn_end(run_obj&nbsp;:&nbsp;Runnable):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(f"on&nbsp;end&nbsp;callback&nbsp;starts&nbsp;at&nbsp;{format_t(time.time())}")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;asyncio.sleep(2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(f"on&nbsp;end&nbsp;callback&nbsp;ends&nbsp;at&nbsp;{format_t(time.time())}")<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;runnable&nbsp;=&nbsp;RunnableLambda(test_runnable).<a href="#ChatVertexAI-with_alisteners">with_alisteners</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;on_start=fn_start,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;on_end=fn_end<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;async&nbsp;def&nbsp;concurrent_runs():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await&nbsp;asyncio.gather(runnable.<a href="#ChatVertexAI-ainvoke">ainvoke</a>(2),&nbsp;runnable.<a href="#ChatVertexAI-ainvoke">ainvoke</a>(3))<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;asyncio.run(concurrent_runs())<br>
&nbsp;&nbsp;&nbsp;&nbsp;Result:<br>
&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;start&nbsp;callback&nbsp;starts&nbsp;at&nbsp;2025-03-01T07:05:22.875378+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;start&nbsp;callback&nbsp;starts&nbsp;at&nbsp;2025-03-01T07:05:22.875495+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;start&nbsp;callback&nbsp;ends&nbsp;at&nbsp;2025-03-01T07:05:25.878862+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;start&nbsp;callback&nbsp;ends&nbsp;at&nbsp;2025-03-01T07:05:25.878947+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;Runnable[2s]:&nbsp;starts&nbsp;at&nbsp;2025-03-01T07:05:25.879392+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;Runnable[3s]:&nbsp;starts&nbsp;at&nbsp;2025-03-01T07:05:25.879804+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;Runnable[2s]:&nbsp;ends&nbsp;at&nbsp;2025-03-01T07:05:27.881998+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;end&nbsp;callback&nbsp;starts&nbsp;at&nbsp;2025-03-01T07:05:27.882360+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;Runnable[3s]:&nbsp;ends&nbsp;at&nbsp;2025-03-01T07:05:28.881737+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;end&nbsp;callback&nbsp;starts&nbsp;at&nbsp;2025-03-01T07:05:28.882428+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;end&nbsp;callback&nbsp;ends&nbsp;at&nbsp;2025-03-01T07:05:29.883893+00:00<br>
&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;end&nbsp;callback&nbsp;ends&nbsp;at&nbsp;2025-03-01T07:05:30.884831+00:00</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-with_config"><strong>with_config</strong></a>(self, config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -&gt; 'Runnable[Input, Output]'</dt><dd><tt>Bind&nbsp;config&nbsp;to&nbsp;a&nbsp;Runnable,&nbsp;returning&nbsp;a&nbsp;new&nbsp;Runnable.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;config:&nbsp;The&nbsp;config&nbsp;to&nbsp;bind&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs:&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;to&nbsp;pass&nbsp;to&nbsp;the&nbsp;Runnable.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;with&nbsp;the&nbsp;config&nbsp;bound.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-with_fallbacks"><strong>with_fallbacks</strong></a>(self, fallbacks: 'Sequence[Runnable[Input, Output]]', *, exceptions_to_handle: 'tuple[type[BaseException], ...]' = (&lt;class 'Exception'&gt;,), exception_key: 'Optional[str]' = None) -&gt; 'RunnableWithFallbacksT[Input, Output]'</dt><dd><tt>Add&nbsp;fallbacks&nbsp;to&nbsp;a&nbsp;Runnable,&nbsp;returning&nbsp;a&nbsp;new&nbsp;Runnable.<br>
&nbsp;<br>
The&nbsp;new&nbsp;Runnable&nbsp;will&nbsp;try&nbsp;the&nbsp;original&nbsp;Runnable,&nbsp;and&nbsp;then&nbsp;each&nbsp;fallback<br>
in&nbsp;order,&nbsp;upon&nbsp;failures.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fallbacks:&nbsp;A&nbsp;sequence&nbsp;of&nbsp;runnables&nbsp;to&nbsp;try&nbsp;if&nbsp;the&nbsp;original&nbsp;Runnable&nbsp;fails.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exceptions_to_handle:&nbsp;A&nbsp;tuple&nbsp;of&nbsp;exception&nbsp;types&nbsp;to&nbsp;handle.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;(Exception,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;exception_key:&nbsp;If&nbsp;string&nbsp;is&nbsp;specified&nbsp;then&nbsp;handled&nbsp;exceptions&nbsp;will&nbsp;be&nbsp;passed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;fallbacks&nbsp;as&nbsp;part&nbsp;of&nbsp;the&nbsp;input&nbsp;under&nbsp;the&nbsp;specified&nbsp;key.&nbsp;If&nbsp;None,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;exceptions&nbsp;will&nbsp;not&nbsp;be&nbsp;passed&nbsp;to&nbsp;fallbacks.&nbsp;If&nbsp;used,&nbsp;the&nbsp;base&nbsp;Runnable<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;its&nbsp;fallbacks&nbsp;must&nbsp;accept&nbsp;a&nbsp;dictionary&nbsp;as&nbsp;input.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;that&nbsp;will&nbsp;try&nbsp;the&nbsp;original&nbsp;Runnable,&nbsp;and&nbsp;then&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;fallback&nbsp;in&nbsp;order,&nbsp;upon&nbsp;failures.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;typing&nbsp;import&nbsp;Iterator<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableGenerator<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;_generate_immediate_error(input:&nbsp;Iterator)&nbsp;-&gt;&nbsp;Iterator[str]:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;raise&nbsp;ValueError()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;yield&nbsp;""<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;_generate(input:&nbsp;Iterator)&nbsp;-&gt;&nbsp;Iterator[str]:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;yield&nbsp;from&nbsp;"foo&nbsp;bar"<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runnable&nbsp;=&nbsp;RunnableGenerator(_generate_immediate_error).<a href="#ChatVertexAI-with_fallbacks">with_fallbacks</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[RunnableGenerator(_generate)]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(''.join(runnable.<a href="#ChatVertexAI-stream">stream</a>({})))&nbsp;#foo&nbsp;bar<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fallbacks:&nbsp;A&nbsp;sequence&nbsp;of&nbsp;runnables&nbsp;to&nbsp;try&nbsp;if&nbsp;the&nbsp;original&nbsp;Runnable&nbsp;fails.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exceptions_to_handle:&nbsp;A&nbsp;tuple&nbsp;of&nbsp;exception&nbsp;types&nbsp;to&nbsp;handle.<br>
&nbsp;&nbsp;&nbsp;&nbsp;exception_key:&nbsp;If&nbsp;string&nbsp;is&nbsp;specified&nbsp;then&nbsp;handled&nbsp;exceptions&nbsp;will&nbsp;be&nbsp;passed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;fallbacks&nbsp;as&nbsp;part&nbsp;of&nbsp;the&nbsp;input&nbsp;under&nbsp;the&nbsp;specified&nbsp;key.&nbsp;If&nbsp;None,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;exceptions&nbsp;will&nbsp;not&nbsp;be&nbsp;passed&nbsp;to&nbsp;fallbacks.&nbsp;If&nbsp;used,&nbsp;the&nbsp;base&nbsp;Runnable<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;its&nbsp;fallbacks&nbsp;must&nbsp;accept&nbsp;a&nbsp;dictionary&nbsp;as&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;that&nbsp;will&nbsp;try&nbsp;the&nbsp;original&nbsp;Runnable,&nbsp;and&nbsp;then&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;fallback&nbsp;in&nbsp;order,&nbsp;upon&nbsp;failures.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-with_listeners"><strong>with_listeners</strong></a>(self, *, on_start: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None, on_end: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None, on_error: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None) -&gt; 'Runnable[Input, Output]'</dt><dd><tt>Bind&nbsp;lifecycle&nbsp;listeners&nbsp;to&nbsp;a&nbsp;Runnable,&nbsp;returning&nbsp;a&nbsp;new&nbsp;Runnable.<br>
&nbsp;<br>
on_start:&nbsp;Called&nbsp;before&nbsp;the&nbsp;Runnable&nbsp;starts&nbsp;running,&nbsp;with&nbsp;the&nbsp;Run&nbsp;object.<br>
on_end:&nbsp;Called&nbsp;after&nbsp;the&nbsp;Runnable&nbsp;finishes&nbsp;running,&nbsp;with&nbsp;the&nbsp;Run&nbsp;object.<br>
on_error:&nbsp;Called&nbsp;if&nbsp;the&nbsp;Runnable&nbsp;throws&nbsp;an&nbsp;error,&nbsp;with&nbsp;the&nbsp;Run&nbsp;object.<br>
&nbsp;<br>
The&nbsp;Run&nbsp;object&nbsp;contains&nbsp;information&nbsp;about&nbsp;the&nbsp;run,&nbsp;including&nbsp;its&nbsp;id,<br>
type,&nbsp;input,&nbsp;output,&nbsp;error,&nbsp;start_time,&nbsp;end_time,&nbsp;and&nbsp;any&nbsp;tags&nbsp;or&nbsp;metadata<br>
added&nbsp;to&nbsp;the&nbsp;run.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;on_start:&nbsp;Called&nbsp;before&nbsp;the&nbsp;Runnable&nbsp;starts&nbsp;running.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;on_end:&nbsp;Called&nbsp;after&nbsp;the&nbsp;Runnable&nbsp;finishes&nbsp;running.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;on_error:&nbsp;Called&nbsp;if&nbsp;the&nbsp;Runnable&nbsp;throws&nbsp;an&nbsp;error.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;with&nbsp;the&nbsp;listeners&nbsp;bound.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.tracers.schemas&nbsp;import&nbsp;Run<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;time<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;test_runnable(time_to_sleep&nbsp;:&nbsp;int):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time.sleep(time_to_sleep)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;fn_start(run_obj:&nbsp;Run):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print("start_time:",&nbsp;run_obj.start_time)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;fn_end(run_obj:&nbsp;Run):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print("end_time:",&nbsp;run_obj.end_time)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;chain&nbsp;=&nbsp;RunnableLambda(test_runnable).<a href="#ChatVertexAI-with_listeners">with_listeners</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;on_start=fn_start,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;on_end=fn_end<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;chain.<a href="#ChatVertexAI-invoke">invoke</a>(2)</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-with_retry"><strong>with_retry</strong></a>(self, *, retry_if_exception_type: 'tuple[type[BaseException], ...]' = (&lt;class 'Exception'&gt;,), wait_exponential_jitter: 'bool' = True, stop_after_attempt: 'int' = 3) -&gt; 'Runnable[Input, Output]'</dt><dd><tt>Create&nbsp;a&nbsp;new&nbsp;Runnable&nbsp;that&nbsp;retries&nbsp;the&nbsp;original&nbsp;Runnable&nbsp;on&nbsp;exceptions.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;retry_if_exception_type:&nbsp;A&nbsp;tuple&nbsp;of&nbsp;exception&nbsp;types&nbsp;to&nbsp;retry&nbsp;on.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Defaults&nbsp;to&nbsp;(Exception,).<br>
&nbsp;&nbsp;&nbsp;&nbsp;wait_exponential_jitter:&nbsp;Whether&nbsp;to&nbsp;add&nbsp;jitter&nbsp;to&nbsp;the&nbsp;wait<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time&nbsp;between&nbsp;retries.&nbsp;Defaults&nbsp;to&nbsp;True.<br>
&nbsp;&nbsp;&nbsp;&nbsp;stop_after_attempt:&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;attempts&nbsp;to&nbsp;make&nbsp;before<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;giving&nbsp;up.&nbsp;Defaults&nbsp;to&nbsp;3.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;that&nbsp;retries&nbsp;the&nbsp;original&nbsp;Runnable&nbsp;on&nbsp;exceptions.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
..&nbsp;code-block::&nbsp;python<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;langchain_core.runnables&nbsp;import&nbsp;RunnableLambda<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;count&nbsp;=&nbsp;0<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;_lambda(x:&nbsp;int)&nbsp;-&gt;&nbsp;None:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;global&nbsp;count<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;count&nbsp;=&nbsp;count&nbsp;+&nbsp;1<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;x&nbsp;==&nbsp;1:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;raise&nbsp;ValueError("x&nbsp;is&nbsp;1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pass<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;runnable&nbsp;=&nbsp;RunnableLambda(_lambda)<br>
&nbsp;&nbsp;&nbsp;&nbsp;try:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runnable.<a href="#ChatVertexAI-with_retry">with_retry</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stop_after_attempt=2,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;retry_if_exception_type=(ValueError,),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;).<a href="#ChatVertexAI-invoke">invoke</a>(1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;except&nbsp;ValueError:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pass<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;assert&nbsp;(count&nbsp;==&nbsp;2)<br>
&nbsp;<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;retry_if_exception_type:&nbsp;A&nbsp;tuple&nbsp;of&nbsp;exception&nbsp;types&nbsp;to&nbsp;retry&nbsp;on<br>
&nbsp;&nbsp;&nbsp;&nbsp;wait_exponential_jitter:&nbsp;Whether&nbsp;to&nbsp;add&nbsp;jitter&nbsp;to&nbsp;the&nbsp;wait&nbsp;time<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;between&nbsp;retries<br>
&nbsp;&nbsp;&nbsp;&nbsp;stop_after_attempt:&nbsp;The&nbsp;maximum&nbsp;number&nbsp;of&nbsp;attempts&nbsp;to&nbsp;make&nbsp;before&nbsp;giving&nbsp;up<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;that&nbsp;retries&nbsp;the&nbsp;original&nbsp;Runnable&nbsp;on&nbsp;exceptions.</tt></dd></dl>

<dl><dt><a name="ChatVertexAI-with_types"><strong>with_types</strong></a>(self, *, input_type: 'Optional[type[Input]]' = None, output_type: 'Optional[type[Output]]' = None) -&gt; 'Runnable[Input, Output]'</dt><dd><tt>Bind&nbsp;input&nbsp;and&nbsp;output&nbsp;types&nbsp;to&nbsp;a&nbsp;Runnable,&nbsp;returning&nbsp;a&nbsp;new&nbsp;Runnable.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;input_type:&nbsp;The&nbsp;input&nbsp;type&nbsp;to&nbsp;bind&nbsp;to&nbsp;the&nbsp;Runnable.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_type:&nbsp;The&nbsp;output&nbsp;type&nbsp;to&nbsp;bind&nbsp;to&nbsp;the&nbsp;Runnable.&nbsp;Defaults&nbsp;to&nbsp;None.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;Runnable&nbsp;with&nbsp;the&nbsp;types&nbsp;bound.</tt></dd></dl>

<hr>
Readonly properties inherited from <a href="langchain_core.runnables.base.html#Runnable">langchain_core.runnables.base.Runnable</a>:<br>
<dl><dt><strong>config_specs</strong></dt>
<dd><tt>List&nbsp;configurable&nbsp;fields&nbsp;for&nbsp;this&nbsp;Runnable.</tt></dd>
</dl>
<dl><dt><strong>input_schema</strong></dt>
<dd><tt>The&nbsp;type&nbsp;of&nbsp;input&nbsp;this&nbsp;Runnable&nbsp;accepts&nbsp;specified&nbsp;as&nbsp;a&nbsp;pydantic&nbsp;model.</tt></dd>
</dl>
<dl><dt><strong>output_schema</strong></dt>
<dd><tt>The&nbsp;type&nbsp;of&nbsp;output&nbsp;this&nbsp;Runnable&nbsp;produces&nbsp;specified&nbsp;as&nbsp;a&nbsp;pydantic&nbsp;model.</tt></dd>
</dl>
<hr>
Class methods inherited from <a href="typing.html#Generic">typing.Generic</a>:<br>
<dl><dt><a name="ChatVertexAI-__init_subclass__"><strong>__init_subclass__</strong></a>(*args, **kwargs)<font color="#909090"><font face="helvetica, arial"> from <a href="pydantic._internal._model_construction.html#ModelMetaclass">pydantic._internal._model_construction.ModelMetaclass</a></font></font></dt><dd><tt>This&nbsp;method&nbsp;is&nbsp;called&nbsp;when&nbsp;a&nbsp;class&nbsp;is&nbsp;subclassed.<br>
&nbsp;<br>
The&nbsp;default&nbsp;implementation&nbsp;does&nbsp;nothing.&nbsp;It&nbsp;may&nbsp;be<br>
overridden&nbsp;to&nbsp;extend&nbsp;subclasses.</tt></dd></dl>

</td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#eeaa77">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Functions</strong></big></font></td></tr>
    
<tr><td bgcolor="#eeaa77"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl><dt><a name="-init_chat_model"><strong>init_chat_model</strong></a>(proxy_client: gen_ai_hub.proxy.core.base.BaseProxyClient, deployment: gen_ai_hub.proxy.gen_ai_hub_proxy.client.Deployment, temperature: float = 0.0, max_tokens: int = 256, top_k: Optional[int] = None, top_p: float = 1.0)</dt></dl>
</td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#55aa55">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Data</strong></big></font></td></tr>
    
<tr><td bgcolor="#55aa55"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><strong>Optional</strong> = typing.Optional<br>
<strong>catalog</strong> = &lt;gen_ai_hub.proxy.langchain.init_models.Catalog object&gt;</td></tr></table>
</body></html>